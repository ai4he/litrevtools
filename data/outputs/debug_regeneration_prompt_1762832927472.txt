
You are an expert in writing PRISMA systematic literature reviews for academic publication.

CRITICAL REQUIREMENT: You MUST cite ALL papers (existing AND new) using LaTeX \cite{} commands throughout the regenerated paper.

=== ALL BIBTEX ENTRIES (INCLUDING NEW PAPERS) ===
@article{cohen2022thisunicorn,
  title={"This is my unicorn, Fluffy": Personalizing frozen vision-language representations},
  author={Niv Cohen and Rinon Gal and E. Meirom and Gal Chechik and Y. Atzmon},
  year={2022},
  booktitle={European Conference on Computer Vision},
  doi={10.48550/arXiv.2204.01694},
  url={https://www.semanticscholar.org/paper/0791a0441e1f672c43aecb2d6708fbc8725c8cad},
  abstract={Large Vision&Language models pretrained on web-scale data provide representations that are invaluable for numerous V&L problems. However, it is unclear how they can be used for reasoning about user-specific visual concepts in unstructured language. This problem arises in multiple domains, from personalized image retrieval to personalized interaction with smart devices. We introduce a new learning setup called Personalized Vision&Language (PerVL) with two new benchmark datasets for retrieving and segmenting user-specific"personalized"concepts"in the wild". In PerVL, one should learn personalized concepts (1) independently of the downstream task (2) allowing a pretrained model to reason about them with free language, and (3) does not require personalized negative examples. We propose an architecture for solving PerVL that operates by extending the input vocabulary of a pretrained model with new word embeddings for the new personalized concepts. The model can then reason about them by simply using them in a sentence. We demonstrate that our approach learns personalized visual concepts from a few examples and can effectively apply them in image retrieval and semantic segmentation using rich textual queries.}
}

@article{stolfo2022causalframework,
  title={A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models},
  author={Alessandro Stolfo and Zhijing Jin and Kumar Shridhar and B. Scholkopf and Mrinmaya Sachan},
  year={2022},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  doi={10.48550/arXiv.2210.12023},
  url={https://www.semanticscholar.org/paper/9b45af10429681249fafb07c3b6012ea4ce63ffe},
  abstract={We have recently witnessed a number of impressive results on hard mathematical reasoning problems with language models. At the same time, the robustness of these models has also been called into question; recent works have shown that models can rely on shallow patterns in the problem description when generating a solution.Building on the idea of behavioral testing, we propose a novel framework, which pins down the causal effect of various factors in the input, e.g., the surface form of the problem text, the operands, and math operators on the output solution.By grounding the behavioral analysis in a causal graph describing an intuitive reasoning process, we study the behavior of language models in terms of robustness and sensitivity to direct interventions in the input space. We apply our framework on a test bed of math word problems.Our analysis shows that robustness does not appear to continuously improve as a function of size, but the GPT-3 Davinci models (175B) achieve a dramatic improvement in both robustness and sensitivity compared to all other GPT variants.}
}

@article{snchez2022clusteringapproach,
  title={A Clustering Approach for the Optimal Siting of Recharging Stations in the Electric Vehicle Routing Problem with Time Windows},
  author={Danny García Sánchez and Alejandra Tabares and L. Faria and Juan Carlos Rivera and J. Franco},
  year={2022},
  booktitle={Energies},
  doi={10.3390/en15072372},
  url={https://www.semanticscholar.org/paper/f1164514c7180331c3b059c19eab5169c9c921a7},
  abstract={Transportation has been incorporating electric vehicles (EVs) progressively. EVs do not produce air or noise pollution, and they have high energy efficiency and low maintenance costs. In this context, the development of efficient techniques to overcome the vehicle routing problem becomes crucial with the proliferation of EVs. The vehicle routing problem concerns the freight capacity and battery autonomy limitations in different delivery-service scenarios, and the challenge of best locating recharging stations. This work proposes a mixed-integer linear programming model to solve the electric location routing problem with time windows (E-LRPTW) considering the state of charge, freight and battery capacities, and customer time windows in the decision model. A clustering strategy based on the k-means algorithm is proposed to divide the set of vertices (EVs) into small areas and define potential sites for recharging stations, while reducing the number of binary variables. The proposed model for E-LRPTW was implemented in Python and solved using mathematical modeling language AMPL together with CPLEX. Performed tests on instances with 5 and 10 clients showed a large reduction in the time required to find the solution (by about 60 times in one instance). It is concluded that the strategy of dividing customers by sectors has the potential to be applied and generate solutions for larger geographical areas and numbers of recharging stations, and determine recharging station locations as part of planning decisions in more realistic scenarios.}
}

@misc{desogus2022contributionrelationship,
  title={A Contribution on Relationship Banking. Economic, Anthropological and Mathematical Reasoning, Empirical Evidence from Italy},
  author={Marco Desogus and Elisa Casu},
  year={2022},
  url={https://www.semanticscholar.org/paper/dd88cc9b1f6d71ef82631b4e1c98c077ccdf291a}
}

@article{wang2022hybridgenetic,
  title={A Hybrid Genetic Algorithm for Flexible Job Shop Scheduling Problem},
  author={Xianglong Wang and Changyi Liu},
  year={2022},
  booktitle={2022 5th World Conference on Mechanical Engineering and Intelligent Manufacturing (WCMEIM)},
  doi={10.1109/WCMEIM56910.2022.10021523},
  url={https://www.semanticscholar.org/paper/3cff420b5a41a06291b68f5b6600935c090f8ad8},
  abstract={Partially flexible job shop scheduling problem (P-FJSP) is a NP Hard problem more complex than fully flexi-ble job shop scheduling problem (T -FJSP). In this paper, the mathematical model of flexible job shop scheduling is established with the goal of minimizing the maximum completion time (makespan). It combines the local search ability of simu-lated annealing algorithm and the global search ability of ge-netic algorithm. In the process of chromosome decoding, greedy decoding method is used to get a better scheduling solution as far as possible. The hybrid scheduling algorithm is implemented based on Visual Studio and C # language. Finally, 8×8 classic scheduling instance are used for simulation scheduling experiments to verify that the hybrid genetic algorithm proposed in this paper is effective in solving large-scale FJSP.}
}

@article{zhang2022multilayerattention,
  title={A Multi-Layer Attention Network for Visual Commonsense Reasoning},
  author={Wenqi Zhang and Yongchao Gao and Heng Qian and Hongli Lyu},
  year={2022},
  booktitle={International Conference on Data Science and Information Technology},
  doi={10.1109/DSIT55514.2022.9943834},
  url={https://www.semanticscholar.org/paper/0e0f20f3af3650b5a97b0ec3f046ba8160b45279},
  abstract={Visual Commonsense Reasoning (VCR) is a challenging multimodal task involving several research fields such as vision, cognition, and reasoning, which combines images and natural language for reasoning. Existing VCR methods focus on global attention or use pre-training models, but these methods lack attention to local features of visual and language. In this paper, a multi-layer attention network is proposed for the VCR task, including an intra-modal attention module and an inter-modal attention module. The intra-modal attention module complements important features of visual and language modalities with fine-grained visual attention to improve the relevance of visual and language. The inter-modal attention module captures the internal dependencies between visual and language. Finally, the two modules are integrated into an end-to-end reasoning framework. Experiments on the VCR large-scale dataset show that the proposed method exhibits a decent improvement in the VCR task and illustrates the effectiveness of the method on three subtasks.}
}

@article{ricci2022petrinetbasedapproach,
  title={A Petri-Net-Based Approach for Enhancing Clinical Reasoning in Medical Education},
  author={F. Ricci and F. Consorti and F. Pecoraro and D. Luzi and Oscar Tamburis},
  year={2022},
  journal={IEEE Transactions on Learning Technologies},
  doi={10.1109/tlt.2022.3157391},
  url={https://www.semanticscholar.org/paper/98b0fb67a6fb222998e3449621f3f5eecaed758e},
  abstract={Medical students are called to acquire competence to manage disease in its dynamic evolution over time, learning to analyze how clinical conditions evolve in a patient's history and how each condition interferes with the evolution of the other coexisting conditions. In this article, the health issue network (HIN) approach is introduced as a formal language based on Petri nets (PNs) to model properties that are particularly apposite for the graphical representation of HIN evolutionary paths. Moreover, the PNs’ underlying mathematical model allows users to draw coherent and well-formed graphs representing rather complex clinical cases. Finally, HIN can be easily integrated into a simulation environment to support case-based learning activities and assessment. The examples of the exercises provided in this article show, on the one hand, the ways the introduced methodology is figured out and implemented; on the other hand, they outline the variety of learning questions that users may deal with when deploying the HIN approach.}
}

@article{ekong2022ratiocinativestudy,
  title={A Ratiocinative Study and Assessment of W. V. O. Quine’s “Criterion of Ontological Commitment”},
  author={Joseph T. Ekong},
  year={2022},
  journal={International Journal of Philosophy},
  doi={10.47941/ijp.1052},
  url={https://www.semanticscholar.org/paper/7b6955111d3bd91b13e7a9c7fbdfd75d43825c36},
  abstract={Purpose: This work has three main objectives: Firstly, it offers an elucidation of the notion of ontological commitment. Secondly, it assesses the adequacy of the criterion of ontological commitment for different languages. Thirdly, it offers some speculative and evaluative remarks regarding the significance of Quine’s criterion of ontological commitment. Many ontologists, within the analytic tradition, often appeal to Quine's criterion of ontological commitment, when debating whether an assertion or theory implies the existence of a certain entity. Regarding his goal in formulating this criterion, he says that the criterion does not aim to help us discover what it is that there is, but only what a theory says there is: “I look to variables and quantification for evidence as to what a theory says that there is, not for evidence as to what there is” (Quine, 1960: 225). Its most popular formulation, using textual evidence from Quine's oeuvre, is: “To be is to be the value of a bound variable,” (Quine, 1961: 15). However, this formulation is susceptible to gross misunderstanding, especially if one is influenced by the formalities and technical maneuvers of model theory. In mathematical logic, model theory is the study of the relationship between formal theories (a collection of sentences in a formal language expressing statements about a mathematical structure), and their models (those structures in which the statements of the theory hold). Model theory is a branch of mathematical logic where we study mathematical structures by considering the first-order sentences true in those structures and the sets definable by first-order formulas. Model theory studies the relations between sentences of a formal language and the interpretations (or ‘structures’) which make these sentences true or false. It offers precise definitions of truth, logical truth and consequence, meanings and modalities. 
Methodology: This work is expository, analytic, critical and evaluative in its methodology. Of course, there are familiar philosophical problems which are within the discursive framework of ‘ontology,’ often phrased by asking if something or some category of things are “real,” or whether “they exist,” concretely. An outstanding example is provided by the traditional problem of universals, which issues in the nominalist-realist controversy, as to the real existence of universals, or of abstract entities such as classes (in the mathematical sense) or propositions (in the abstract sense, referring to the content of an assertion in abstraction from the particular words used to convey it). 
Results: In as much as one might agree with Quine’s Criterion of Ontological Commitment, one might also opine that it is nonetheless a feature of first-order language (i.e. the language embodied in first-order logic; a symbolized reasoning process comprising relations, functions and constants, in which each sentence or statement is broken down into a subject and a predicate. In this regard, the predicate modifies or defines the properties of the subject) that there should be an exact correspondence between the ontological commitments carried by a sentence and the objects that must be counted among the values of the variables in order for the sentence to be true. However, this in itself is not a reason for thinking that such a feature will generalize beyond first-order languages. It is possible for Quine’s Criterion to degenerate, when the language contains atomic predicates expressing extrinsic properties. 
Unique Contribution to theory, practice and policy: Based on Quine’s analysis, a theory is committed to those and only those entities that in the last analysis serve as the values of its bound variables. Thus, ordinary first-order theory commits one to an ontology only of individuals (particulars), whereas higher order logic commits one to the existence of sets, i.e. of collections of definite and distinct entities (or, alternatively, of properties and relations). Likewise, if bound first-order variables are assumed to range over sets (as they do in set theory), a commitment to the existence of these sets is incurred. Admittedly, the precise import of Quine’s criterion of ontological commitment, however, is not completely clear, nor is it clear in what other sense one is perhaps committed by a theory to those entities that are named or otherwise referred to in it, but not quantified over in it. However, it despite its limitations, it has made is possible for one to measure the ontological cost of theories, an important component in deciding which theories to accept, thus offering a partial foundation for theory choice.}
}

@article{li2022scenariobasedexploration,
  title={A Scenario-based Exploration of Expected Usefulness, Privacy Concerns, and Adoption Likelihood of Learning Analytics},
  author={X. Li and M. Rosson and Jenay Robert},
  year={2022},
  booktitle={ACM Conference on Learning @ Scale},
  doi={10.1145/3491140.3528271},
  url={https://www.semanticscholar.org/paper/067b8489b028d931b751cb9413225b761e51dcf3},
  abstract={Learning analytics has become a robust research area in the last decade, as innovative analytic models of learning data have been created with the goal of enhancing teaching and learning. However, barriers to large scale adoption of such technologies in higher education still exist. In recent years, a strand of research has begun to investigate stakeholders' expectations of learning analytics, hoping to find ways to integrate the innovations into everyday teaching practices. For instance, studies have investigated instructors' ideas about how learning analytics might be helpful, as well as concerns about student data privacy. However, most studies have taken a general approach rather than considering instructors' day-to-day experiences. Using survey methods, we presented instructors with hypothetical scenarios of learning analytics in use across disciplines, class sizes, teaching activities, and types of student data. We asked for ratings of both usefulness and privacy concerns for each proposed teaching situation. Our respondents considered scenarios involving learning outcomes-related data (e.g. grades) to be more useful than those that involve student interactions (e.g. language, social activity). In contrast, privacy concerns were lower for outcomes-oriented scenarios than interactions-focused scenarios. An interesting new finding was a negative correlation of usefulness and privacy; we discuss this in the context of instructors' possible cost-benefit reasoning. We reflect on our findings with respect to future efforts in developing and fielding learning analytics tools.}
}

@article{lu2022surveydeep,
  title={A Survey of Deep Learning for Mathematical Reasoning},
  author={Pan Lu and Liang Qiu and Wenhao Yu and S. Welleck and Kai-Wei Chang},
  year={2022},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  doi={10.48550/arXiv.2212.10535},
  url={https://www.semanticscholar.org/paper/2dbec38fe353ab0e495ad09263389dbc9260824d},
  abstract={Mathematical reasoning is a fundamental aspect of human intelligence and is applicable in various fields, including science, engineering, finance, and everyday life. The development of artificial intelligence (AI) systems capable of solving math problems and proving theorems in language has garnered significant interest in the fields of machine learning and natural language processing. For example, mathematics serves as a testbed for aspects of reasoning that are challenging for powerful deep learning models, driving new algorithmic and modeling advances. On the other hand, recent advances in large-scale neural language models have opened up new benchmarks and opportunities to use deep learning for mathematical reasoning. In this survey paper, we review the key tasks, datasets, and methods at the intersection of mathematical reasoning and deep learning over the past decade. We also evaluate existing benchmarks and methods, and discuss future research directions in this domain.}
}

@article{hu2022surveyknowledge,
  title={A Survey of Knowledge Enhanced Pre-Trained Language Models},
  author={Linmei Hu and Zeyi Liu and Ziwang Zhao and Lei Hou and Liqiang Nie and Juanzi Li},
  year={2022},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  doi={10.1109/TKDE.2023.3310002},
  url={https://www.semanticscholar.org/paper/a26623d52d24e03044a158cddad931ec5ab7304c},
  abstract={Pre-trained Language Models (PLMs) which are trained on large text corpus via self-supervised learning method, have yielded promising performance on various tasks in Natural Language Processing (NLP). However, though PLMs with huge parameters can effectively possess rich knowledge learned from massive training text and benefit downstream tasks at the fine-tuning stage, they still have some limitations such as poor reasoning ability due to the lack of external knowledge. Research has been dedicated to incorporating knowledge into PLMs to tackle these issues. In this paper, we present a comprehensive review of Knowledge Enhanced Pre-trained Language Models (KE-PLMs) to provide a clear insight into this thriving field. We introduce appropriate taxonomies respectively for Natural Language Understanding (NLU) and Natural Language Generation (NLG) to highlight these two main tasks of NLP. For NLU, we divide the types of knowledge into four categories: linguistic knowledge, text knowledge, knowledge graph (KG), and rule knowledge. The KE-PLMs for NLG are categorized into KG-based and retrieval-based methods. Finally, we point out some promising future directions of KE-PLMs.}
}

@article{zhou2022surveyneural,
  title={A Survey on Neural Open Information Extraction: Current Status and Future Directions},
  author={Shaowen Zhou and Yu Bowen and Aixin Sun and Cheng Long and Jingyang Li and Haiyang Yu and Jianguo Sun},
  year={2022},
  booktitle={International Joint Conference on Artificial Intelligence},
  doi={10.48550/arXiv.2205.11725},
  url={https://www.semanticscholar.org/paper/5de6ecf62f14c9263882f9f30d6448df9efd34e0},
  abstract={Open Information Extraction (OpenIE) facilitates domain-independent discovery of relational facts from large corpora. The technique well suits many open-world natural language understanding scenarios, such as automatic knowledge base construction, open-domain question answering, and explicit reasoning. Thanks to the rapid development in deep learning technologies, numerous neural OpenIE architectures have been proposed and achieve considerable performance improvement. In this survey, we provide an extensive overview of the state-of-the-art neural OpenIE models, their key design decisions, strengths and weakness. Then, we discuss limitations of current solutions and the open issues in OpenIE problem itself. Finally we list recent trends that could help expand its scope and applicability, setting up promising directions for future research in OpenIE. To our best knowledge, this paper is the first review on neural OpenIE.}
}

@article{wankmller2022comparisonapproaches,
  title={A comparison of approaches for imbalanced classification problems in the context of retrieving relevant documents for an analysis},
  author={Sandra Wankmüller},
  year={2022},
  journal={Journal of Computational Social Science},
  doi={10.1007/s42001-022-00191-7},
  url={https://www.semanticscholar.org/paper/a12e9a6863c8453787575172599389d2ddcd9f62},
  abstract={One of the first steps in many text-based social science studies is to retrieve documents that are relevant for an analysis from large corpora of otherwise irrelevant documents. The conventional approach in social science to address this retrieval task is to apply a set of keywords and to consider those documents to be relevant that contain at least one of the keywords. But the application of incomplete keyword lists has a high risk of drawing biased inferences. More complex and costly methods such as query expansion techniques, topic model-based classification rules, and active as well as passive supervised learning could have the potential to more accurately separate relevant from irrelevant documents and thereby reduce the potential size of bias. Yet, whether applying these more expensive approaches increases retrieval performance compared to keyword lists at all, and if so, by how much, is unclear as a comparison of these approaches is lacking. This study closes this gap by comparing these methods across three retrieval tasks associated with a data set of German tweets (Linder in SSRN, 2017. https://doi.org/10.2139/ssrn.3026393 ), the Social Bias Inference Corpus (SBIC) (Sap et al. in Social bias frames: reasoning about social and power implications of language. In: Jurafsky et al. (eds) Proceedings of the 58th annual meeting of the association for computational linguistics. Association for Computational Linguistics, p 5477–5490, 2020. https://doi.org/10.18653/v1/2020.aclmain.486 ), and the Reuters-21578 corpus (Lewis in Reuters-21578 (Distribution 1.0). [Data set], 1997. http://www.daviddlewis.com/resources/testcollections/reuters21578/ ). Results show that query expansion techniques and topic model-based classification rules in most studied settings tend to decrease rather than increase retrieval performance. Active supervised learning, however, if applied on a not too small set of labeled training instances (e.g. 1000 documents), reaches a substantially higher retrieval performance than keyword lists.}
}

@article{wang2022comparisonthree,
  title={A comparison of three approaches to covariate effects on latent factors},
  author={Ze Wang},
  year={2022},
  booktitle={Large-scale Assessments in Education},
  doi={10.1186/s40536-022-00148-2},
  url={https://www.semanticscholar.org/paper/c40412109167ae57baab6505edf9b628efca6d3a},
  abstract={In educational and psychological research, it is common to use latent factors to represent constructs and then to examine covariate effects on these latent factors. Using empirical data, this study applied three approaches to covariate effects on latent factors: the multiple-indicator multiple-cause (MIMIC) approach, multiple group confirmatory factor analysis (MG-CFA) approach, and the structural equation model trees (SEM Trees) approach. The MIMIC approach directly models covariate effects on latent factors. The MG-CFA approach allows testing of measurement invariance before latent factor means could be compared. The more recently developed SEM Trees approach partitions the sample into homogenous subsets based on the covariate space; model parameters are estimated separately for each subgroup. We applied the three approaches using an empirical dataset extracted from the eighth-grade U.S. data from the Trends in International Mathematics and Science Study 2019 database. All approaches suggested differences among mathematics achievement categories for the latent factor of mathematics self-concept. In addition, language spoken at home did not seem to affect students’ mathematics self-concept. Despite these general findings, the three approaches provided different pieces of information regarding covariate effects. For all models, we appropriately considered the complex data structure and sampling weights following recent recommendations for analyzing large-scale assessment data.}
}

@misc{alemany2022methodologycharacterize,
  title={A methodology to characterize bias and harmful stereotypes in natural language processing in Latin America},
  author={L. A. Alemany and Luciana Benotti and Hernán Maina and Luc'ia M. Gonz'alez and Mariela Rajngewerc and Lautaro Mart'inez and Jos'e L. S'anchez and M. Schilman and Guido Ivetta and Alexia Halvorsen and Amanda Rojo and M. Bordone and Beatriz Busaniche},
  year={2022},
  url={https://www.semanticscholar.org/paper/a82a08b5e6a11f4d6fdff95dd30177957ed7855e},
  abstract={Automated decision-making systems, especially those based on natural language processing, are pervasive in our lives. They are not only behind the internet search engines we use daily, but also take more critical roles: selecting candidates for a job, determining suspects of a crime, diagnosing autism and more. Such automated systems make errors, which may be harmful in many ways, be it because of the severity of the consequences (as in health issues) or because of the sheer number of people they affect. When errors made by an automated system affect a population more than others, we call the system \textit{biased}. Most modern natural language technologies are based on artifacts obtained from enormous volumes of text using machine learning, namely language models and word embeddings. Since they are created by applying subsymbolic machine learning, mostly artificial neural networks, they are opaque and practically uninterpretable by direct inspection, thus making it very difficult to audit them. In this paper, we present a methodology that spells out how social scientists, domain experts, and machine learning experts can collaboratively explore biases and harmful stereotypes in word embeddings and large language models. Our methodology is based on the following principles: * focus on the linguistic manifestations of discrimination on word embeddings and language models, not on the mathematical properties of the models * reduce the technical barrier for discrimination experts%, be it social scientists, domain experts or other * characterize through a qualitative exploratory process in addition to a metric-based approach * address mitigation as part of the training process, not as an afterthought}
}

@article{kim2022novelmodular,
  title={A novel modular modeling approach for understanding different electromechanics between left and right heart in rat},
  author={Nari Kim and Julius D. Pronto and D. Nickerson and A. Taberner and Peter J. Hunter},
  year={2022},
  booktitle={Frontiers in Physiology},
  doi={10.3389/fphys.2022.965054},
  url={https://www.semanticscholar.org/paper/2fba0d7b1293e4b13180fb3bccf86ed52ddcaf70},
  abstract={While ion channels and transporters involved in excitation-contraction coupling have been linked and constructed as comprehensive computational models, validation of whether each individual component of a model can be reused has not been previously attempted. Here we address this issue while using a novel modular modeling approach to investigate the underlying mechanism for the differences between left ventricle (LV) and right ventricle (RV). Our model was developed from modules constructed using the module assembly principles of the CellML model markup language. The components of three existing separate models of cardiac function were disassembled as to create smaller modules, validated individually, and then the component parts were combined into a new integrative model of a rat ventricular myocyte. The model was implemented in OpenCOR using the CellML standard in order to ensure reproducibility. Simulated action potential (AP), Ca2+ transient, and tension were in close agreement with our experimental measurements: LV AP showed a prolonged duration and a more prominent plateau compared with RV AP; Ca2+ transient showed prolonged duration and slow decay in LV compared to RV; the peak value and relaxation of tension were larger and slower, respectively, in LV compared to RV. Our novel approach of module-based mathematical modeling has established that the ionic mechanisms underlying the APs and Ca2+ handling play a role in the variation in force production between ventricles. This simulation process also provides a useful way to reuse and elaborate upon existing models in order to develop a new model.}
}

@article{mi2022reviewdevelopment,
  title={A review: development of named entity recognition (NER) technology for aeronautical information intelligence},
  author={Baigang Mi and Fan Yi},
  year={2022},
  booktitle={Artificial Intelligence Review},
  doi={10.1007/s10462-022-10197-2},
  url={https://www.semanticscholar.org/paper/ca2da2420fd25c8633641542730d3f0867c50f60}
}

@article{poythress2022semioticanalysis,
  title={A semiotic analysis of multiple systems of logic: using tagmemic theory to assess the usefulness and limitations of formal logics, and to produce a mathematical lattice model including multiple systems of logic},
  author={V. Poythress},
  year={2022},
  journal={Semiotica: Journal of the International Association for Semiotic Studies},
  doi={10.1515/sem-2020-0051},
  url={https://www.semanticscholar.org/paper/606db29a9d5cad5cd06b8eeb1f8beee390c87ca4},
  abstract={Abstract Tagmemic theory as a semiotic theory can be used to analyze multiple systems of logic and to assess their strengths and weaknesses. This analysis constitutes an application of semiotics and also a contribution to understanding of the nature of logic within the context of human meaning. Each system of logic is best adapted to represent one portion of human rationality. Acknowledging this correlation between systems and their targets helps explain the usefulness of more than one system. Among these systems, the two-valued system of classical logic takes its place. All the systems of logic can be incorporated into a complex mathematical model that has a place for each system and that represents a larger whole in human reasoning. The model can represent why tight formal systems of logic can be applied in some contexts with great success, but in other contexts are not directly applicable. The result suggests that human reasoning is innately richer than any one formal system of logic.}
}

@misc{song2022thesissubmitted,
  title={A thesis submitted to the Faculty of Graduate and Postdoctoral Affairs in partial fulfillment of the requirements for the degree of Master of Arts},
  author={Charlene Song},
  year={2022},
  url={https://www.semanticscholar.org/paper/25be22274b72f1337e977d94d0c94026d13a67d0}
}

@article{markta2022accuracypupils,
  title={ACCURACY OF PUPILS´ SELF-ASSESSMENT},
  author={Švamberk Šauerová Markéta and Smetáčková Irena},
  year={2022},
  booktitle={EduPort},
  doi={10.21062/edp.2022.009},
  url={https://www.semanticscholar.org/paper/fcfabc1d551304cde28a4f0658ed20e36559e05f},
  abstract={In this study, we investigated the accuracy of pupils´ self-assessment in two main school domains – mathematics and Czech language. The analysis explores whether pupils are able to evaluate adequately their own results in the didactic tests and then use some individual parameters to explain the level of self-assessment. The aim of the study was to analyze whether groups of pupils with different self-assessments of school tasks in the Czech language and mathematics (significant underestimation, adequate self-assessment, significant overestimation) differ in some of the cognitive skills studied. Our study questions were as follows: (1) Do pupils assess their achievements in particular school tasks accurately, or inaccurately? (2) Do pupils´ self-assessments differ in mathematics and language? (3) Do the pupil´s self-assessment correlate with individual parameters? The main tool used in the study was a didactic test on mathematics and a didactic test on the Czech language based on the Czech National Curricula Document and created by an expert team. In addition, Raven's Color Progressive Matrices (CPM), Similarities from the Wechsler Intelligence (WISC-SIM), and the Rey-Osterrieth Complex Figure (ROCF) were used. Considering the nature of the data, the non-parametric Kruskal-Wallis ANOVA was used. The present study is a part of the larger research project, involving 29 primary school classes, 657 pupils in total. Based on the data obtained, it can be concluded that the accuracy of pupils' self-assessments is low, while the accuracy of pupils' self-assessments in mathematics and Czech language differs (in mathematics there are more children with more accurate estimates and more pupils who underestimate themselves, in Czech language there are more pupils who overestimate their performance. Statistically significant differences were observed in the domains of Raven's Color Progressive Matrices and Rey-Osterrieth Figure, and in terms of the focus of each test, it could be concluded that there are significant differences between the groups in the domain of non-verbal reasoning skills and in the domain of analytical and organizational perceptual activity and memory. In the area of verbal intellectual abilities, there were no significant differences between the groups.}
}

@article{ji2022afrbertattentionbased,
  title={AFR-BERT: Attention-based mechanism feature relevance fusion multimodal sentiment analysis model},
  author={Mingyu Ji and Jiawei Zhou and Wei Ning},
  year={2022},
  booktitle={PLoS ONE},
  doi={10.1371/journal.pone.0273936},
  url={https://www.semanticscholar.org/paper/918f34bd4274316d684dd6c267b13fe010a74a6e},
  abstract={Multimodal sentiment analysis is an essential task in natural language processing which refers to the fact that machines can analyze and recognize emotions through logical reasoning and mathematical operations after learning multimodal emotional features. For the problem of how to consider the effective fusion of multimodal data and the relevance of multimodal data in multimodal sentiment analysis, we propose an attention-based mechanism feature relevance fusion multimodal sentiment analysis model (AFR-BERT). In the data pre-processing stage, text features are extracted using the pre-trained language model BERT (Bi-directional Encoder Representation from Transformers), and the BiLSTM (Bi-directional Long Short-Term Memory) is used to obtain the internal information of the audio. In the data fusion phase, the multimodal data fusion network effectively fuses multimodal features through the interaction of text and audio information. During the data analysis phase, the multimodal data association network analyzes the data by exploring the correlation of fused information between text and audio. In the data output phase, the model outputs the results of multimodal sentiment analysis. We conducted extensive comparative experiments on the publicly available sentiment analysis datasets CMU-MOSI and CMU-MOSEI. The experimental results show that AFR-BERT improves on the classical multimodal sentiment analysis model in terms of relevant performance metrics. In addition, ablation experiments and example analysis show that the multimodal data analysis network in AFR-BERT can effectively capture and analyze the sentiment features in text and audio.}
}

@article{gulwani2022aiassistedprogramming,
  title={AI-assisted programming: applications, user experiences, and neuro-symbolic techniques (keynote)},
  author={Sumit Gulwani},
  year={2022},
  booktitle={ESEC/SIGSOFT FSE},
  doi={10.1145/3540250.3569444},
  url={https://www.semanticscholar.org/paper/11230f03465d8ab073815397717d8afa3f3dae1c}
}

@article{yu2022alertadapt,
  title={ALERT: Adapt Language Models to Reasoning Tasks},
  author={Ping Yu and Tianlu Wang and O. Yu. Golovneva and Badr AlKhamissi and Gargi Ghosh and Mona T. Diab and Asli Celikyilmaz},
  year={2022},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  doi={10.48550/arXiv.2212.08286},
  url={https://www.semanticscholar.org/paper/95c11cc5820ba32c60d5f2671f6567b9914a4978},
  abstract={Recent advancements in large language models have enabled them to perform well on complex tasks that require step-by-step reasoning with few-shot learning. However, it is unclear whether these models are applying reasoning skills they have learnt during pre-training , or if they are simply memorizing their training corpus at finer granularity and have learnt to better understand their context.To address this question, we introduce {pasted macro ‘OUR’}model, a benchmark and suite of analyses for evaluating reasoning skills of language models. {pasted macro ‘OUR’}model enables comparing pre-trained and finetuned models on complex tasks that require reasoning skills to solve. Our benchmark provides a test bed to asses any language model on fine-grained reasoning skills, which spans over 20 datasets and covers 10 different reasoning skills. By using {pasted macro ‘OUR’}model we further investigate the role of finetuning. Our extensive empirical analysis shows that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogical reasoning during the finetuning stage compared to pretraining stage. However, we also find that when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models causing generalization problems.}
}

@article{2022algorithmmethod,
  title={ALGORITHM METHOD IN TEACHING RUSSIAN AT SECONDARY SCHOOL},
  author={Юлия Владимировна Подкина},
  year={2022},
  booktitle={Tomsk state pedagogical university bulletin},
  doi={10.23951/1609-624x-2022-6-80-87},
  url={https://www.semanticscholar.org/paper/ded393f5b3432f3d0b9258fff2b9db33b204bf84},
  abstract={Введение. Обучение русскому языку в средней школе, развитие речи и формирование орфографических и пунктуационных навыков – важная задача, которая сопряжена с рядом трудностей. Эффективному изучению русского языка в общеобразовательной школе зачастую препятствуют такие факторы, как плохая усидчивость, отсутствие интереса к предмету, билингвизм и другое. Метод алгоритмизированного представления правил русской орфографии и пунктуации способствует наилучшему усвоению учебного материала и позволяет повысить качество обучения русскому языку школьников среднего и старшего звена. Цель − обоснование эффективности метода алгоритма в обучении русскому языку детей общеобразовательных средних школ, рассмотрение примерных моделей обучающих алгоритмов. Материал и методы. В работе применялись теоретические методы (моделирование, анализ, синтез); эмпирические методы (наблюдение, сравнение, эксперимент). Результаты и обсуждение. Простое заучивание правил не всегда приводит к повышению грамотности учащихся. Метод алгоритма предусматривает совместное с учениками составление алгоритмизированных схем различных видов, которые иллюстрируют изучаемое правило, позволяют пошагово отработать механизм рассуждения при выполнении орфографических и пунктуационных заданий. Такой подход способствует достижению высокого качества знаний путем систематической отработки практических навыков с помощью схем, адаптируемых под потребности каждого ребенка. Обучающий алгоритм может иметь разные виды: от четко сформулированной схемы (похожей на математический пример) до красочной иллюстрации, которая будет понятна детям с творческими способностями. Заключение. Метод алгоритма применяют для изучения практически любого правила русской орфографии и пунктуации. В созданной совместно с учащимися схеме должно быть отведено место для исключений и для примеров, которые ребенок впишет самостоятельно. При создании обучающей схемы школьник является активным соавтором. Схема никогда не является замкнутой системой. Она дорабатывается и совершенствуется в процессе практической деятельности учащихся. У детей из одного класса схемы могут быть совершенно различны, так как усовершенствованы и доработаны самостоятельно под руководством учителя.
 Introduction. Teaching Russian in secondary school, speech development and the formation of spelling and punctuation skills is an important task that involves a number of difficulties. Effective study of the Russian language in a secondary school is often hindered by factors such as poor perseverance, lack of interest in the subject, bilingualism, and more. Russian Russian spelling rules algorithmized representation method is considered in this paper, which allows to improve the quality of teaching Russian to middle and senior school students. The purpose is to substantiate the effectiveness of the algorithm method in teaching the Russian language to children of secondary schools, to consider approximate models of training algorithms. Material and methods. Theoretical methods (modeling, analysis, synthesis) were used in the work; empirical methods (observation, comparison, experiment). Results and discussion. Simple memorizing of the rules does not always lead to increased literacy of students. The algorithm method provides for the joint compilation of algorithmic schemes of various types with students, which illustrate the rule being studied, allow you to work out the mechanism of reasoning step by step when performing spelling and punctuation tasks. This approach contributes to the achievement of a high quality of knowledge through the systematic development of practical skills with the help of schemes adapted to the needs of each child. The training algorithm can have different types: from a clearly formulated scheme (similar to a mathematical example) up to a colorful illustration that will be understandable to children with creative abilities. Conclusion. The algorithm method can be applied to study almost any rule of Russian spelling and punctuation. In the scheme created jointly with the students, there should be a place for exceptions and for examples that the child will enter independently. When creating a training scheme, the student is an active co-author. A circuit is never a closed system. It is being refined and improved in the process of practical activity of students. For children from the same class, the schemes can be completely different, as they have been improved and finalized independently.}
}

@article{mare2022updatethermal,
  title={AN UPDATE OF THERMAL ERROR COMPENSATION MODEL VIA ON-MACHINE MEASUREMENT},
  author={M. Mareš and O. Horejš and Michal Straka and J. Švéda and Tomáš Kozlok},
  year={2022},
  journal={MM Science Journal},
  doi={10.17973/mmsj.2022_12_2022150},
  url={https://www.semanticscholar.org/paper/796f47a4059604f27ad57c3760cc7ebea9f6a020},
  abstract={Software compensation is state-of-the-art technology used to reduce CNC machine tool thermal errors, and it belongs to a key intelligent functions of modern machine tools. However, a pretrained and nonadaptive model may not be accurate and robust enough for long-term application. This research presents a transfer function based thermal error compensation model updated via on-machine measurement. A mathematical model is implemented into the machine management software of a large horizontal machining centre to compensate for thermal errors in real time using C#/C++ programming language. The results show that after the thermal error compensation model is updated via on-machine measurement, the prediction accuracy, measured as peak-to-peak values, and the normalized root mean squared error are significantly improved. The prediction accuracy of the compensation model updated via on-machine measurement strongly depends on the sampling interval of the on machine measurements.}
}

@misc{nam2022achievingunderstanding,
  title={Achieving and Understanding Out-of-Distribution Generalization in Systematic Reasoning in Small-Scale Transformers},
  author={A. Nam and Mustafa Abdool and Trevor Maxfield and James L. McClelland},
  year={2022},
  url={https://www.semanticscholar.org/paper/8283064365ae7594d891e8b7daf36fd37ca809b0},
  abstract={Out-of-distribution generalization (OODG) is a longstanding challenge for neural networks. This challenge is quite apparent in tasks with well-defined variables and rules, where explicit use of the rules could solve problems independently of the particular values of the variables, but networks tend to be tied to the range of values sampled in their training data. Large transformer-based language models have pushed the boundaries on how well neural networks can solve previously unseen problems, but their complexity and lack of clarity about the relevant content in their training data obfuscates how they achieve such robustness. As a step toward understanding how transformer-based systems generalize, we explore the question of OODG in small scale transformers trained with examples from a known distribution. Using a reasoning task based on the puzzle Sudoku, we show that OODG can occur on a complex problem if the training set includes examples sampled from the whole distribution of simpler component tasks. Successful generalization depends on carefully managing positional alignment when absolute position encoding is used, but we find that suppressing sensitivity to absolute positions overcomes this limitation. Taken together our results represent a small step toward understanding and promoting systematic generalization in transformers.}
}

@article{hppner2022advantagesdisadvantages,
  title={Advantages and disadvantages of (dedicated) model transformation languages},
  author={S. Höppner and Yves Haas and Matthias Tichy and Katharina Juhnke},
  year={2022},
  booktitle={Empirical Software Engineering},
  doi={10.1007/s10664-022-10194-7},
  url={https://www.semanticscholar.org/paper/d96fa397010fa107aadcedbff577feead334e3be},
  abstract={Model driven development envisages the use of model transformations to evolve models. Model transformation languages, developed for this task, are touted with many benefits over general purpose programming languages. However, a large number of these claims have not yet been substantiated. They are also made without the context necessary to be able to critically assess their merit or built meaningful empirical studies around them. The objective of our work is to elicit the reasoning, influences and background knowledge that lead people to assume benefits or drawbacks of model transformation languages. We conducted a large-scale interview study involving 56 participants from research and industry. Interviewees were presented with claims about model transformation languages and were asked to provide reasons for their assessment thereof. We qualitatively analysed the responses to find factors that influence the properties of model transformation languages as well as explanations as to how exactly they do so. Our interviews show, that general purpose expressiveness of GPLs, domain specific capabilities of MTLs as well as tooling all have strong influences on how people view properties of model transformation languages. Moreover, the Choice of MTL, the Use Case for which a transformation should be developed as well as the Skill s of involved stakeholders have a moderating effect on the influences, by changing the context to consider. There is a broad body of experience, that suggests positive and negative influences for properties of MTLs. Our data suggests, that much needs to be done in order to convey the viability of model transformation languages. Efforts to provide more empirical substance need to be undergone and lacklustre language capabilities and tooling need to be improved upon. We suggest several approaches for this that can be based on the results of the presented study.}
}

@article{abramson2022applicationpseudologlikelihoods,
  title={An Application of Pseudo-Log-Likelihoods to Natural Language Scoring},
  author={Darren Abramson and Ali Emami},
  year={2022},
  booktitle={arXiv.org},
  url={https://www.semanticscholar.org/paper/16bf88a6d172699cb9a26a6936efb4941e3f3c13},
  abstract={Language models built using semi-supervised machine learning on large corpora of natural language have very quickly enveloped the fields of natural language generation and understanding. In this paper we apply a zero-shot approach independently developed by a number of researchers now gaining recognition as a significant alternative to fine-tuning for evaluation on common sense tasks. A language model with relatively few parameters and training steps compared to a more recent language model (T5) can outperform it on a recent large data set (TimeDial), while displaying robustness in its performance across a similar class of language tasks. Surprisingly, this result is achieved by using a hyperparameter-free zero-shot method with the smaller model, compared to fine-tuning to the larger model. We argue that robustness of the smaller model ought to be understood in terms of compositionality, in a sense that we draw from recent literature on a class of similar models. We identify a practical cost for our method and model: high GPU-time for natural language evaluation. The zero-shot measurement technique that produces remarkable stability, both for ALBERT and other BERT variants, is an application of pseudo-log-likelihoods to masked language models for the relative measurement of probability for substitution alternatives in forced choice language tasks such as the Winograd Schema Challenge, Winogrande, and others. One contribution of this paper is to bring together a number of similar, but independent strands of research. We produce some absolute state-of-the-art results for common sense reasoning in binary choice tasks, performing better than any published result in the literature, including fine-tuned efforts. We show a remarkable consistency of the model's performance under adversarial settings, which we argue is best explained by the model's compositionality of representations.}
}

@article{zhang2022empiricalinvestigation,
  title={An Empirical Investigation of Commonsense Self-Supervision with Knowledge Graphs},
  author={Jiarui Zhang and Filip Ilievski and Kaixin Ma and Jonathan M Francis and A. Oltramari},
  year={2022},
  booktitle={arXiv.org},
  doi={10.48550/arXiv.2205.10661},
  url={https://www.semanticscholar.org/paper/651ae53112e73b02440773727b68cedbf8322705},
  abstract={Self-supervision based on the information extracted from large knowledge graphs has been shown to improve the generalization of language models, in zero-shot evaluation on various downstream language reasoning tasks. Since these improvements are reported in aggregate, however, little is known about (i) how to select the appropriate knowledge for solid performance across tasks, (ii) how to combine this knowledge with neural language models, and (iii) how these pairings affect granular task performance. In this paper, we study the effect of knowledge sampling strategies and sizes that can be used to generate synthetic data for adapting language models. We study the effect of different synthetic datasets on language models with various architectures and sizes. The resulting models are evaluated against four task properties: domain overlap, answer similarity, vocabulary overlap, and answer length. Our experiments show that encoder-decoder models benefit from more data to learn from, whereas sampling strategies that balance across different aspects yield best performance. Most of the improvement occurs on questions with short answers and dissimilar answer candidates, which corresponds to the characteristics of the data used for pre-training.}
}

@article{khan2022executableformal,
  title={An Executable Formal Model of the VHDL in Isabelle/HOL},
  author={Wilayat Khan and Zhé Hóu and David Sanán and J. Nebhen and Yang Liu and Alwen Tiu},
  year={2022},
  booktitle={arXiv.org},
  url={https://www.semanticscholar.org/paper/37b0b6db785f8c37460e2bb80da138c1443af5b4},
  abstract={In the hardware design process, hardware components are usually described in a hardware description language. Most of the hardware description languages, such as Verilog and VHDL, do not have mathematical foundation and hence are not fit for formal reasoning about the design. To enable formal reasoning in one of the most commonly used description language VHDL, we define a formal model of the VHDL language in Isabelle/HOL. Our model targets the functional part of VHDL designs used in industry, specifically the design of the LEON3 processor's integer unit. We cover a wide range of features in the VHDL language that are usually not modelled in the literature and define a novel operational semantics for it. Furthermore, our model can be exported to OCaml code for execution, turning the formal model into a VHDL simulator. We have tested our simulator against simple designs used in the literature, as well as the div32 module in the LEON3 design. The Isabelle/HOL code is publicly available: https://zhehou.github.io/apps/VHDLModel.zip}
}

=== END BIBTEX ENTRIES ===

=== NEW PAPERS BEING ADDED THIS ITERATION ===
@article{kim2022novelmodular,
  title={A novel modular modeling approach for understanding different electromechanics between left and right heart in rat},
  author={Nari Kim and Julius D. Pronto and D. Nickerson and A. Taberner and Peter J. Hunter},
  year={2022},
  booktitle={Frontiers in Physiology},
  doi={10.3389/fphys.2022.965054},
  url={https://www.semanticscholar.org/paper/2fba0d7b1293e4b13180fb3bccf86ed52ddcaf70},
  abstract={While ion channels and transporters involved in excitation-contraction coupling have been linked and constructed as comprehensive computational models, validation of whether each individual component of a model can be reused has not been previously attempted. Here we address this issue while using a novel modular modeling approach to investigate the underlying mechanism for the differences between left ventricle (LV) and right ventricle (RV). Our model was developed from modules constructed using the module assembly principles of the CellML model markup language. The components of three existing separate models of cardiac function were disassembled as to create smaller modules, validated individually, and then the component parts were combined into a new integrative model of a rat ventricular myocyte. The model was implemented in OpenCOR using the CellML standard in order to ensure reproducibility. Simulated action potential (AP), Ca2+ transient, and tension were in close agreement with our experimental measurements: LV AP showed a prolonged duration and a more prominent plateau compared with RV AP; Ca2+ transient showed prolonged duration and slow decay in LV compared to RV; the peak value and relaxation of tension were larger and slower, respectively, in LV compared to RV. Our novel approach of module-based mathematical modeling has established that the ionic mechanisms underlying the APs and Ca2+ handling play a role in the variation in force production between ventricles. This simulation process also provides a useful way to reuse and elaborate upon existing models in order to develop a new model.}
}

@article{mi2022reviewdevelopment,
  title={A review: development of named entity recognition (NER) technology for aeronautical information intelligence},
  author={Baigang Mi and Fan Yi},
  year={2022},
  booktitle={Artificial Intelligence Review},
  doi={10.1007/s10462-022-10197-2},
  url={https://www.semanticscholar.org/paper/ca2da2420fd25c8633641542730d3f0867c50f60}
}

@article{poythress2022semioticanalysis,
  title={A semiotic analysis of multiple systems of logic: using tagmemic theory to assess the usefulness and limitations of formal logics, and to produce a mathematical lattice model including multiple systems of logic},
  author={V. Poythress},
  year={2022},
  journal={Semiotica: Journal of the International Association for Semiotic Studies},
  doi={10.1515/sem-2020-0051},
  url={https://www.semanticscholar.org/paper/606db29a9d5cad5cd06b8eeb1f8beee390c87ca4},
  abstract={Abstract Tagmemic theory as a semiotic theory can be used to analyze multiple systems of logic and to assess their strengths and weaknesses. This analysis constitutes an application of semiotics and also a contribution to understanding of the nature of logic within the context of human meaning. Each system of logic is best adapted to represent one portion of human rationality. Acknowledging this correlation between systems and their targets helps explain the usefulness of more than one system. Among these systems, the two-valued system of classical logic takes its place. All the systems of logic can be incorporated into a complex mathematical model that has a place for each system and that represents a larger whole in human reasoning. The model can represent why tight formal systems of logic can be applied in some contexts with great success, but in other contexts are not directly applicable. The result suggests that human reasoning is innately richer than any one formal system of logic.}
}

@misc{song2022thesissubmitted,
  title={A thesis submitted to the Faculty of Graduate and Postdoctoral Affairs in partial fulfillment of the requirements for the degree of Master of Arts},
  author={Charlene Song},
  year={2022},
  url={https://www.semanticscholar.org/paper/25be22274b72f1337e977d94d0c94026d13a67d0}
}

@article{markta2022accuracypupils,
  title={ACCURACY OF PUPILS´ SELF-ASSESSMENT},
  author={Švamberk Šauerová Markéta and Smetáčková Irena},
  year={2022},
  booktitle={EduPort},
  doi={10.21062/edp.2022.009},
  url={https://www.semanticscholar.org/paper/fcfabc1d551304cde28a4f0658ed20e36559e05f},
  abstract={In this study, we investigated the accuracy of pupils´ self-assessment in two main school domains – mathematics and Czech language. The analysis explores whether pupils are able to evaluate adequately their own results in the didactic tests and then use some individual parameters to explain the level of self-assessment. The aim of the study was to analyze whether groups of pupils with different self-assessments of school tasks in the Czech language and mathematics (significant underestimation, adequate self-assessment, significant overestimation) differ in some of the cognitive skills studied. Our study questions were as follows: (1) Do pupils assess their achievements in particular school tasks accurately, or inaccurately? (2) Do pupils´ self-assessments differ in mathematics and language? (3) Do the pupil´s self-assessment correlate with individual parameters? The main tool used in the study was a didactic test on mathematics and a didactic test on the Czech language based on the Czech National Curricula Document and created by an expert team. In addition, Raven's Color Progressive Matrices (CPM), Similarities from the Wechsler Intelligence (WISC-SIM), and the Rey-Osterrieth Complex Figure (ROCF) were used. Considering the nature of the data, the non-parametric Kruskal-Wallis ANOVA was used. The present study is a part of the larger research project, involving 29 primary school classes, 657 pupils in total. Based on the data obtained, it can be concluded that the accuracy of pupils' self-assessments is low, while the accuracy of pupils' self-assessments in mathematics and Czech language differs (in mathematics there are more children with more accurate estimates and more pupils who underestimate themselves, in Czech language there are more pupils who overestimate their performance. Statistically significant differences were observed in the domains of Raven's Color Progressive Matrices and Rey-Osterrieth Figure, and in terms of the focus of each test, it could be concluded that there are significant differences between the groups in the domain of non-verbal reasoning skills and in the domain of analytical and organizational perceptual activity and memory. In the area of verbal intellectual abilities, there were no significant differences between the groups.}
}

@article{ji2022afrbertattentionbased,
  title={AFR-BERT: Attention-based mechanism feature relevance fusion multimodal sentiment analysis model},
  author={Mingyu Ji and Jiawei Zhou and Wei Ning},
  year={2022},
  booktitle={PLoS ONE},
  doi={10.1371/journal.pone.0273936},
  url={https://www.semanticscholar.org/paper/918f34bd4274316d684dd6c267b13fe010a74a6e},
  abstract={Multimodal sentiment analysis is an essential task in natural language processing which refers to the fact that machines can analyze and recognize emotions through logical reasoning and mathematical operations after learning multimodal emotional features. For the problem of how to consider the effective fusion of multimodal data and the relevance of multimodal data in multimodal sentiment analysis, we propose an attention-based mechanism feature relevance fusion multimodal sentiment analysis model (AFR-BERT). In the data pre-processing stage, text features are extracted using the pre-trained language model BERT (Bi-directional Encoder Representation from Transformers), and the BiLSTM (Bi-directional Long Short-Term Memory) is used to obtain the internal information of the audio. In the data fusion phase, the multimodal data fusion network effectively fuses multimodal features through the interaction of text and audio information. During the data analysis phase, the multimodal data association network analyzes the data by exploring the correlation of fused information between text and audio. In the data output phase, the model outputs the results of multimodal sentiment analysis. We conducted extensive comparative experiments on the publicly available sentiment analysis datasets CMU-MOSI and CMU-MOSEI. The experimental results show that AFR-BERT improves on the classical multimodal sentiment analysis model in terms of relevant performance metrics. In addition, ablation experiments and example analysis show that the multimodal data analysis network in AFR-BERT can effectively capture and analyze the sentiment features in text and audio.}
}

@article{gulwani2022aiassistedprogramming,
  title={AI-assisted programming: applications, user experiences, and neuro-symbolic techniques (keynote)},
  author={Sumit Gulwani},
  year={2022},
  booktitle={ESEC/SIGSOFT FSE},
  doi={10.1145/3540250.3569444},
  url={https://www.semanticscholar.org/paper/11230f03465d8ab073815397717d8afa3f3dae1c}
}

@article{yu2022alertadapt,
  title={ALERT: Adapt Language Models to Reasoning Tasks},
  author={Ping Yu and Tianlu Wang and O. Yu. Golovneva and Badr AlKhamissi and Gargi Ghosh and Mona T. Diab and Asli Celikyilmaz},
  year={2022},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  doi={10.48550/arXiv.2212.08286},
  url={https://www.semanticscholar.org/paper/95c11cc5820ba32c60d5f2671f6567b9914a4978},
  abstract={Recent advancements in large language models have enabled them to perform well on complex tasks that require step-by-step reasoning with few-shot learning. However, it is unclear whether these models are applying reasoning skills they have learnt during pre-training , or if they are simply memorizing their training corpus at finer granularity and have learnt to better understand their context.To address this question, we introduce {pasted macro ‘OUR’}model, a benchmark and suite of analyses for evaluating reasoning skills of language models. {pasted macro ‘OUR’}model enables comparing pre-trained and finetuned models on complex tasks that require reasoning skills to solve. Our benchmark provides a test bed to asses any language model on fine-grained reasoning skills, which spans over 20 datasets and covers 10 different reasoning skills. By using {pasted macro ‘OUR’}model we further investigate the role of finetuning. Our extensive empirical analysis shows that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogical reasoning during the finetuning stage compared to pretraining stage. However, we also find that when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models causing generalization problems.}
}

@article{2022algorithmmethod,
  title={ALGORITHM METHOD IN TEACHING RUSSIAN AT SECONDARY SCHOOL},
  author={Юлия Владимировна Подкина},
  year={2022},
  booktitle={Tomsk state pedagogical university bulletin},
  doi={10.23951/1609-624x-2022-6-80-87},
  url={https://www.semanticscholar.org/paper/ded393f5b3432f3d0b9258fff2b9db33b204bf84},
  abstract={Введение. Обучение русскому языку в средней школе, развитие речи и формирование орфографических и пунктуационных навыков – важная задача, которая сопряжена с рядом трудностей. Эффективному изучению русского языка в общеобразовательной школе зачастую препятствуют такие факторы, как плохая усидчивость, отсутствие интереса к предмету, билингвизм и другое. Метод алгоритмизированного представления правил русской орфографии и пунктуации способствует наилучшему усвоению учебного материала и позволяет повысить качество обучения русскому языку школьников среднего и старшего звена. Цель − обоснование эффективности метода алгоритма в обучении русскому языку детей общеобразовательных средних школ, рассмотрение примерных моделей обучающих алгоритмов. Материал и методы. В работе применялись теоретические методы (моделирование, анализ, синтез); эмпирические методы (наблюдение, сравнение, эксперимент). Результаты и обсуждение. Простое заучивание правил не всегда приводит к повышению грамотности учащихся. Метод алгоритма предусматривает совместное с учениками составление алгоритмизированных схем различных видов, которые иллюстрируют изучаемое правило, позволяют пошагово отработать механизм рассуждения при выполнении орфографических и пунктуационных заданий. Такой подход способствует достижению высокого качества знаний путем систематической отработки практических навыков с помощью схем, адаптируемых под потребности каждого ребенка. Обучающий алгоритм может иметь разные виды: от четко сформулированной схемы (похожей на математический пример) до красочной иллюстрации, которая будет понятна детям с творческими способностями. Заключение. Метод алгоритма применяют для изучения практически любого правила русской орфографии и пунктуации. В созданной совместно с учащимися схеме должно быть отведено место для исключений и для примеров, которые ребенок впишет самостоятельно. При создании обучающей схемы школьник является активным соавтором. Схема никогда не является замкнутой системой. Она дорабатывается и совершенствуется в процессе практической деятельности учащихся. У детей из одного класса схемы могут быть совершенно различны, так как усовершенствованы и доработаны самостоятельно под руководством учителя.
 Introduction. Teaching Russian in secondary school, speech development and the formation of spelling and punctuation skills is an important task that involves a number of difficulties. Effective study of the Russian language in a secondary school is often hindered by factors such as poor perseverance, lack of interest in the subject, bilingualism, and more. Russian Russian spelling rules algorithmized representation method is considered in this paper, which allows to improve the quality of teaching Russian to middle and senior school students. The purpose is to substantiate the effectiveness of the algorithm method in teaching the Russian language to children of secondary schools, to consider approximate models of training algorithms. Material and methods. Theoretical methods (modeling, analysis, synthesis) were used in the work; empirical methods (observation, comparison, experiment). Results and discussion. Simple memorizing of the rules does not always lead to increased literacy of students. The algorithm method provides for the joint compilation of algorithmic schemes of various types with students, which illustrate the rule being studied, allow you to work out the mechanism of reasoning step by step when performing spelling and punctuation tasks. This approach contributes to the achievement of a high quality of knowledge through the systematic development of practical skills with the help of schemes adapted to the needs of each child. The training algorithm can have different types: from a clearly formulated scheme (similar to a mathematical example) up to a colorful illustration that will be understandable to children with creative abilities. Conclusion. The algorithm method can be applied to study almost any rule of Russian spelling and punctuation. In the scheme created jointly with the students, there should be a place for exceptions and for examples that the child will enter independently. When creating a training scheme, the student is an active co-author. A circuit is never a closed system. It is being refined and improved in the process of practical activity of students. For children from the same class, the schemes can be completely different, as they have been improved and finalized independently.}
}

@article{mare2022updatethermal,
  title={AN UPDATE OF THERMAL ERROR COMPENSATION MODEL VIA ON-MACHINE MEASUREMENT},
  author={M. Mareš and O. Horejš and Michal Straka and J. Švéda and Tomáš Kozlok},
  year={2022},
  journal={MM Science Journal},
  doi={10.17973/mmsj.2022_12_2022150},
  url={https://www.semanticscholar.org/paper/796f47a4059604f27ad57c3760cc7ebea9f6a020},
  abstract={Software compensation is state-of-the-art technology used to reduce CNC machine tool thermal errors, and it belongs to a key intelligent functions of modern machine tools. However, a pretrained and nonadaptive model may not be accurate and robust enough for long-term application. This research presents a transfer function based thermal error compensation model updated via on-machine measurement. A mathematical model is implemented into the machine management software of a large horizontal machining centre to compensate for thermal errors in real time using C#/C++ programming language. The results show that after the thermal error compensation model is updated via on-machine measurement, the prediction accuracy, measured as peak-to-peak values, and the normalized root mean squared error are significantly improved. The prediction accuracy of the compensation model updated via on-machine measurement strongly depends on the sampling interval of the on machine measurements.}
}

@misc{nam2022achievingunderstanding,
  title={Achieving and Understanding Out-of-Distribution Generalization in Systematic Reasoning in Small-Scale Transformers},
  author={A. Nam and Mustafa Abdool and Trevor Maxfield and James L. McClelland},
  year={2022},
  url={https://www.semanticscholar.org/paper/8283064365ae7594d891e8b7daf36fd37ca809b0},
  abstract={Out-of-distribution generalization (OODG) is a longstanding challenge for neural networks. This challenge is quite apparent in tasks with well-defined variables and rules, where explicit use of the rules could solve problems independently of the particular values of the variables, but networks tend to be tied to the range of values sampled in their training data. Large transformer-based language models have pushed the boundaries on how well neural networks can solve previously unseen problems, but their complexity and lack of clarity about the relevant content in their training data obfuscates how they achieve such robustness. As a step toward understanding how transformer-based systems generalize, we explore the question of OODG in small scale transformers trained with examples from a known distribution. Using a reasoning task based on the puzzle Sudoku, we show that OODG can occur on a complex problem if the training set includes examples sampled from the whole distribution of simpler component tasks. Successful generalization depends on carefully managing positional alignment when absolute position encoding is used, but we find that suppressing sensitivity to absolute positions overcomes this limitation. Taken together our results represent a small step toward understanding and promoting systematic generalization in transformers.}
}

@article{hppner2022advantagesdisadvantages,
  title={Advantages and disadvantages of (dedicated) model transformation languages},
  author={S. Höppner and Yves Haas and Matthias Tichy and Katharina Juhnke},
  year={2022},
  booktitle={Empirical Software Engineering},
  doi={10.1007/s10664-022-10194-7},
  url={https://www.semanticscholar.org/paper/d96fa397010fa107aadcedbff577feead334e3be},
  abstract={Model driven development envisages the use of model transformations to evolve models. Model transformation languages, developed for this task, are touted with many benefits over general purpose programming languages. However, a large number of these claims have not yet been substantiated. They are also made without the context necessary to be able to critically assess their merit or built meaningful empirical studies around them. The objective of our work is to elicit the reasoning, influences and background knowledge that lead people to assume benefits or drawbacks of model transformation languages. We conducted a large-scale interview study involving 56 participants from research and industry. Interviewees were presented with claims about model transformation languages and were asked to provide reasons for their assessment thereof. We qualitatively analysed the responses to find factors that influence the properties of model transformation languages as well as explanations as to how exactly they do so. Our interviews show, that general purpose expressiveness of GPLs, domain specific capabilities of MTLs as well as tooling all have strong influences on how people view properties of model transformation languages. Moreover, the Choice of MTL, the Use Case for which a transformation should be developed as well as the Skill s of involved stakeholders have a moderating effect on the influences, by changing the context to consider. There is a broad body of experience, that suggests positive and negative influences for properties of MTLs. Our data suggests, that much needs to be done in order to convey the viability of model transformation languages. Efforts to provide more empirical substance need to be undergone and lacklustre language capabilities and tooling need to be improved upon. We suggest several approaches for this that can be based on the results of the presented study.}
}

@article{abramson2022applicationpseudologlikelihoods,
  title={An Application of Pseudo-Log-Likelihoods to Natural Language Scoring},
  author={Darren Abramson and Ali Emami},
  year={2022},
  booktitle={arXiv.org},
  url={https://www.semanticscholar.org/paper/16bf88a6d172699cb9a26a6936efb4941e3f3c13},
  abstract={Language models built using semi-supervised machine learning on large corpora of natural language have very quickly enveloped the fields of natural language generation and understanding. In this paper we apply a zero-shot approach independently developed by a number of researchers now gaining recognition as a significant alternative to fine-tuning for evaluation on common sense tasks. A language model with relatively few parameters and training steps compared to a more recent language model (T5) can outperform it on a recent large data set (TimeDial), while displaying robustness in its performance across a similar class of language tasks. Surprisingly, this result is achieved by using a hyperparameter-free zero-shot method with the smaller model, compared to fine-tuning to the larger model. We argue that robustness of the smaller model ought to be understood in terms of compositionality, in a sense that we draw from recent literature on a class of similar models. We identify a practical cost for our method and model: high GPU-time for natural language evaluation. The zero-shot measurement technique that produces remarkable stability, both for ALBERT and other BERT variants, is an application of pseudo-log-likelihoods to masked language models for the relative measurement of probability for substitution alternatives in forced choice language tasks such as the Winograd Schema Challenge, Winogrande, and others. One contribution of this paper is to bring together a number of similar, but independent strands of research. We produce some absolute state-of-the-art results for common sense reasoning in binary choice tasks, performing better than any published result in the literature, including fine-tuned efforts. We show a remarkable consistency of the model's performance under adversarial settings, which we argue is best explained by the model's compositionality of representations.}
}

@article{zhang2022empiricalinvestigation,
  title={An Empirical Investigation of Commonsense Self-Supervision with Knowledge Graphs},
  author={Jiarui Zhang and Filip Ilievski and Kaixin Ma and Jonathan M Francis and A. Oltramari},
  year={2022},
  booktitle={arXiv.org},
  doi={10.48550/arXiv.2205.10661},
  url={https://www.semanticscholar.org/paper/651ae53112e73b02440773727b68cedbf8322705},
  abstract={Self-supervision based on the information extracted from large knowledge graphs has been shown to improve the generalization of language models, in zero-shot evaluation on various downstream language reasoning tasks. Since these improvements are reported in aggregate, however, little is known about (i) how to select the appropriate knowledge for solid performance across tasks, (ii) how to combine this knowledge with neural language models, and (iii) how these pairings affect granular task performance. In this paper, we study the effect of knowledge sampling strategies and sizes that can be used to generate synthetic data for adapting language models. We study the effect of different synthetic datasets on language models with various architectures and sizes. The resulting models are evaluated against four task properties: domain overlap, answer similarity, vocabulary overlap, and answer length. Our experiments show that encoder-decoder models benefit from more data to learn from, whereas sampling strategies that balance across different aspects yield best performance. Most of the improvement occurs on questions with short answers and dissimilar answer candidates, which corresponds to the characteristics of the data used for pre-training.}
}

@article{khan2022executableformal,
  title={An Executable Formal Model of the VHDL in Isabelle/HOL},
  author={Wilayat Khan and Zhé Hóu and David Sanán and J. Nebhen and Yang Liu and Alwen Tiu},
  year={2022},
  booktitle={arXiv.org},
  url={https://www.semanticscholar.org/paper/37b0b6db785f8c37460e2bb80da138c1443af5b4},
  abstract={In the hardware design process, hardware components are usually described in a hardware description language. Most of the hardware description languages, such as Verilog and VHDL, do not have mathematical foundation and hence are not fit for formal reasoning about the design. To enable formal reasoning in one of the most commonly used description language VHDL, we define a formal model of the VHDL language in Isabelle/HOL. Our model targets the functional part of VHDL designs used in industry, specifically the design of the LEON3 processor's integer unit. We cover a wide range of features in the VHDL language that are usually not modelled in the literature and define a novel operational semantics for it. Furthermore, our model can be exported to OCaml code for execution, turning the formal model into a VHDL simulator. We have tested our simulator against simple designs used in the literature, as well as the div32 module in the LEON3 design. The Isabelle/HOL code is publicly available: https://zhehou.github.io/apps/VHDLModel.zip}
}

=== END NEW PAPERS ===

PREVIOUS DRAFT OF THE PAPER:
=== ABSTRACT ===
This systematic literature review examines the intersection of large language models (LLMs) and mathematical reasoning. We provide a comprehensive overview of the current landscape, identifying key tasks, datasets, and methodologies. The review highlights advancements in LLMs' ability to perform mathematical operations, solve word problems, and even engage in more complex forms of mathematical deduction. We explore various approaches, including fine-tuning, prompt engineering, and the integration of external knowledge sources, to enhance LLM performance in this domain. The findings underscore the significant progress made in leveraging LLMs for mathematical tasks, while also pointing to remaining challenges in areas such as robustness, interpretability, and generalization to novel mathematical concepts. This review serves as a valuable resource for researchers and practitioners interested in the evolving capabilities of LLMs in mathematical reasoning.

=== INTRODUCTION ===
\section{Introduction}

Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide spectrum of natural language processing tasks, from text generation to complex question answering \cite{brown2020language}. A particularly challenging and important domain where LLMs are increasingly being applied is mathematical reasoning. The ability to understand, process, and generate mathematical content is fundamental to scientific discovery, engineering, finance, and many aspects of daily life. Consequently, the development of artificial intelligence systems capable of robust mathematical reasoning has been a long-standing goal in the field of AI \cite{lu2022surveydeep}.

Recent advancements in LLMs, particularly those based on transformer architectures \cite{vaswani2017attention}, have opened new avenues for tackling complex mathematical problems. These models, trained on massive datasets, possess an emergent ability to perform arithmetic operations, solve algebraic equations, and even engage with more abstract mathematical concepts. However, the robustness and reliability of LLMs in mathematical reasoning remain active areas of research. Issues such as susceptibility to superficial patterns in problem descriptions \cite{stolfo2022causalframework} and the need for explicit reasoning capabilities \cite{zhang2022multilayerattention} highlight the ongoing challenges.

This systematic literature review aims to provide a comprehensive overview of the current state of research at the intersection of large language models and mathematical reasoning. We address the following research questions:

1. What are the primary tasks and datasets used to evaluate LLMs in mathematical reasoning?
2. What are the dominant methodologies and architectures employed to enhance LLM performance in mathematical reasoning?
3. What are the key findings and limitations of current research in this area?
4. What are the promising future research directions for LLMs in mathematical reasoning?

To address these questions, we conducted a systematic search of the literature. Our methodology, detailed in the following section, adheres to the principles of the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) statement \cite{moher2009preferred} to ensure transparency and reproducibility. We focused on original research articles that specifically investigated the application of LLMs to mathematical reasoning tasks, excluding survey and review papers.

This paper is structured as follows: Section 2 details our methodology. Section 3 presents the results of our literature search, organized thematically. Section 4 discusses the findings, identifies research gaps, and outlines implications and future directions. Finally, Section 5 concludes the review by summarizing the key contributions and insights.

=== METHODOLOGY ===
\section{Methodology}

This systematic literature review was conducted following the PRISMA guidelines to ensure a comprehensive and transparent search and selection process \cite{moher2009preferred}. The review focused on identifying research that investigates the application of large language models (LLMs) to mathematical reasoning tasks.

\subsection{Search Strategy}

Our search strategy was designed to capture relevant literature from major academic databases. We utilized the following search terms, combined using Boolean operators:

* (large language model OR LLM) AND (mathematical reasoning OR math reasoning OR quantitative reasoning OR problem solving OR algebra OR calculus OR arithmetic)

The primary databases searched were IEEE Xplore, ACM Digital Library, SpringerLink, and Google Scholar. The search was restricted to publications from 2018 to the present to capture the most recent advancements, given the rapid evolution of LLMs.

\subsection{Inclusion and Exclusion Criteria}

To ensure the relevance and quality of the included studies, we defined strict inclusion and exclusion criteria:

*   **Inclusion Criteria:**
    *   The study must explicitly involve large language models (e.g., GPT-3, BERT variants, T5, etc.).
    *   The study must focus on mathematical reasoning tasks, which include but are not limited to arithmetic, algebra, geometry, calculus, logical reasoning in mathematical contexts, and solving mathematical word problems.
    *   The study must present original research, including experimental results, novel methodologies, or analyses.
    *   The study must be published in English.

*   **Exclusion Criteria:**
    *   Survey or review articles.
    *   Studies focusing solely on natural language processing tasks unrelated to mathematical reasoning.
    *   Studies that do not explicitly use or analyze LLMs.
    *   Workshop papers, conference abstracts without full papers, and non-peer-reviewed articles.
    *   Studies where mathematical reasoning is a minor component and not the primary focus.

\subsection{Study Selection}

Following the initial search, all retrieved records were imported into a reference management software. Titles and abstracts were systematically screened by two independent reviewers based on the defined inclusion and exclusion criteria. Any disagreements were resolved through discussion or consultation with a senior researcher. Full texts of potentially relevant articles were then retrieved and assessed for final inclusion. This process aimed to identify studies that met all the criteria for inclusion.

\subsection{Data Extraction and Synthesis}

Data extraction involved identifying key information from each included study, such as the LLM used, the specific mathematical reasoning task, the dataset employed, the proposed methodology, and the main findings. Due to the diverse nature of the research questions and methodologies within this field, a meta-analysis was not feasible. Instead, a narrative synthesis approach was adopted to summarize and integrate the findings. The results were organized thematically to provide a structured overview of the research landscape.

\subsection{Quality Assessment}

While a formal quality assessment tool was not applied to every paper, the selection process implicitly prioritized studies with clear methodologies, robust experimental designs, and statistically sound results. The focus on peer-reviewed publications also served as a proxy for quality. The PRISMA guidelines recommend assessing the risk of bias, and our meticulous screening process aimed to minimize bias in study selection.

=== RESULTS ===
\section{Results}

Our systematic literature search identified a significant volume of research at the intersection of large language models and mathematical reasoning. A total of 462 records were initially identified, and after applying our strict inclusion and exclusion criteria, all 462 records were deemed relevant and included in this review. This high inclusion rate reflects the extensive and focused research in this specialized area over the past few years.

\subsection{Publication Trends and Key Venues}

The research in this domain has seen a substantial increase in publications, particularly in the last two to three years, coinciding with the rapid advancements in LLM capabilities. The majority of the research is published in top-tier artificial intelligence and natural language processing conferences and journals, including the proceedings of the Association for Computational Linguistics (ACL), Conference on Empirical Methods in Natural Language Processing (EMNLP), and NeurIPS, as well as prominent journals like the Journal of Artificial Intelligence Research and IEEE Transactions.

\subsection{Core Tasks and Datasets}

Several core tasks form the backbone of evaluating LLMs in mathematical reasoning. These include:

*   **Arithmetic Reasoning:** Tasks involving basic and complex arithmetic operations, often found in datasets like GSM8K and MATH \cite{hendrycks2021math}.
*   **Algebraic Problem Solving:** Solving equations, inequalities, and manipulating algebraic expressions.
*   **Mathematical Word Problems:** Understanding natural language descriptions of mathematical scenarios and formulating solutions. This is a particularly challenging area, requiring both natural language understanding and mathematical computation \cite{lu2022surveydeep}.
*   **Commonsense Mathematical Reasoning:** Applying everyday knowledge to solve mathematical problems that may not have explicit mathematical formulations.

Datasets such as GSM8K \cite{kobelski2022rethinking} and MATH \cite{hendrycks2021math} are frequently used benchmarks for evaluating LLMs' performance on these tasks. The complexity of these datasets ranges from elementary school math problems to advanced high school and early undergraduate level mathematics.

\subsection{Methodologies for Enhancing Mathematical Reasoning}

Researchers have explored various methodologies to improve LLMs' mathematical reasoning capabilities. These can be broadly categorized as follows:

\subsubsection{Prompt Engineering and In-Context Learning}

This approach involves carefully crafting prompts to guide the LLM towards better reasoning. Techniques like chain-of-thought (CoT) prompting have shown significant improvements by encouraging the model to generate intermediate reasoning steps, mimicking human problem-solving processes \cite{wei2022chainofthought}. For example, models prompted with CoT can decompose complex problems into smaller, manageable steps, leading to more accurate solutions.

\subsubsection{Fine-tuning Pre-trained Models}

Fine-tuning large pre-trained models on specific mathematical datasets has been a prevalent strategy. This allows the models to adapt their parameters to the nuances of mathematical language and reasoning. Studies have demonstrated that fine-tuning LLMs on datasets like GSM8K can significantly boost their performance on arithmetic and algebraic problems \cite{kobelski2022rethinking}.

\subsubsection{Integration of External Tools and Knowledge}

Some approaches integrate LLMs with external tools such as calculators, symbolic solvers (e.g., Wolfram Alpha), or knowledge graphs. This hybrid approach leverages the LLM's natural language understanding capabilities and the precision of specialized tools. For instance, an LLM can translate a word problem into a query for a symbolic solver, thus overcoming the LLM's inherent limitations in exact computation \cite{lu2022surveydeep}.

\subsubsection{Knowledge Enhancement}

Incorporating external knowledge, such as mathematical definitions, theorems, or formulas, into LLMs can also improve their reasoning abilities. Knowledge-enhanced pre-trained language models (KE-PLMs) aim to bridge the gap between parametric knowledge learned from text and explicit external knowledge \cite{hu2022surveyknowledge}. This can involve methods like knowledge graph embedding or retrieval-augmented generation.

\subsubsection{Causal Reasoning and Robustness}

Ensuring the robustness of LLMs' mathematical reasoning is critical. Researchers are investigating causal frameworks to understand how different components of a problem description influence the model's output, aiming to prevent reliance on spurious correlations \cite{stolfo2022causalframework}. This is particularly important for identifying potential biases or weaknesses in the model's reasoning process.

\subsubsection{Personalization in Vision-Language Models}

While not strictly mathematical reasoning, some work explores personalization in vision-language models, which can involve understanding user-specific concepts described in language. This highlights the broader trend of adapting LLMs to specific contexts, which could extend to personalized mathematical tutoring or problem-solving assistance \cite{cohen2022thisunicorn}.

\subsubsection{Hybrid Algorithms and Optimization}

In more applied domains, hybrid algorithms combining LLM-like approaches with optimization techniques are being explored. For example, in scheduling problems, hybrid genetic algorithms are used to optimize complex tasks, demonstrating how LLM principles might be integrated into broader problem-solving frameworks \cite{wang2022hybridgenetic}. Similarly, clustering approaches are used to optimize complex routing problems with time windows, showcasing the application of advanced computational methods \cite{snchez2022clusteringapproach}.

\subsubsection{Formal Methods and Clinical Reasoning}

In specialized fields, formal methods like Petri nets are being used to enhance reasoning capabilities, such as in clinical reasoning for medical education. This demonstrates the diverse applications of structured reasoning, which LLMs might eventually complement or emulate \cite{ricci2022petrinetbasedapproach}.

\subsubsection{Ontological Commitment and Reasoning}

Philosophical and linguistic analyses of reasoning, such as W. V. O. Quine's criterion of ontological commitment, provide theoretical underpinnings for understanding what it means for a theory or model to commit to certain entities or concepts \cite{ekong2022ratiocinativestudy}. This abstract form of reasoning is fundamental to constructing logical and consistent systems.

\subsubsection{Bias and Stereotypes in NLP}

Research on characterizing bias and harmful stereotypes in NLP systems, including LLMs, is crucial for ensuring fair and equitable applications. Methodologies are being developed to collaboratively explore biases with social scientists and domain experts, focusing on linguistic manifestations rather than solely mathematical properties of the models \cite{alemany2022methodologycharacterize}. This awareness is vital when applying LLMs to tasks that have societal implications, including those involving quantitative data.

\subsubsection{Learning Analytics and Privacy Concerns}

In educational contexts, the adoption of learning analytics technologies involves exploring expected usefulness and privacy concerns. Scenario-based explorations help understand how instructors perceive the value of data-driven insights versus potential privacy risks, influencing the adoption of these technologies \cite{li2022scenariobasedexploration}.

\subsubsection{Comparison of Approaches for Imbalanced Classification}

In text-based analysis, comparing different approaches for imbalanced classification, such as keyword-based retrieval versus supervised learning, is essential for accurate document retrieval relevant for analysis \cite{wankmller2022comparisonapproaches}. Similarly, comparing different statistical modeling approaches for covariate effects on latent factors in educational research is vital for robust findings \cite{wang2022comparisonthree}.

=== DISCUSSION ===
\section{Discussion}

The findings from this systematic review highlight the significant advancements and the evolving landscape of large language models (LLMs) in mathematical reasoning. The research consistently shows that LLMs, particularly when augmented with techniques like chain-of-thought prompting \cite{wei2022chainofthought} and fine-tuning on specialized datasets \cite{kobelski2022rethinking}, are making considerable progress in tasks ranging from basic arithmetic to solving complex word problems \cite{lu2022surveydeep}.

One of the most prominent themes is the efficacy of prompting strategies. Chain-of-thought prompting, by encouraging explicit step-by-step reasoning, has proven to be a powerful method for unlocking LLMs' latent mathematical capabilities \cite{wei2022chainofthought}. This approach moves beyond simple input-output mappings and allows models to emulate a more human-like problem-solving process. Furthermore, the integration of LLMs with external tools like calculators or symbolic solvers represents a pragmatic approach to overcome the inherent limitations of neural networks in precise computation \cite{lu2022surveydeep}.

Despite these advancements, several research gaps and challenges persist. **Robustness** remains a critical concern. As demonstrated by \cite{stolfo2022causalframework}, LLMs can sometimes rely on shallow patterns in problem statements rather than genuine mathematical understanding. This lack of true reasoning poses risks, especially in safety-critical applications. There is a continuous need for methodologies that can ensure LLMs' mathematical reasoning is grounded and reliable, not easily fooled by adversarial examples or superficial correlations.

Another significant gap lies in the **generalization capabilities** of LLMs to novel mathematical domains or more advanced theoretical concepts. While current models excel at tasks they have been trained on, their ability to perform abstract mathematical reasoning, discover new theorems, or understand complex proofs remains limited. Research into **knowledge enhancement** \cite{hu2022surveyknowledge} and more sophisticated reasoning architectures is crucial to address this. The challenge is to move beyond pattern recognition and develop models that can truly understand and manipulate mathematical structures.

**Interpretability and explainability** of LLM reasoning processes are also areas requiring further attention. While techniques like chain-of-thought provide some level of transparency, understanding the internal mechanisms by which LLMs arrive at a mathematical solution is still an open problem. This is vital for debugging, building trust, and advancing the theoretical understanding of AI's reasoning capabilities. Similar to efforts in understanding bias in NLP \cite{alemany2022methodologycharacterize}, more focus is needed on making the reasoning process of LLMs auditable.

The potential for **personalization** in LLM applications, as suggested by work in vision-language models \cite{cohen2022thisunicorn}, opens up exciting avenues for personalized mathematical education or assistance. However, this also necessitates careful consideration of data privacy and ethical implications, analogous to concerns raised in learning analytics \cite{li2022scenariobasedexploration}.

Future research should continue to focus on developing more robust, generalizable, and interpretable LLMs for mathematical reasoning. Exploring novel architectures, incorporating formal verification methods, and developing more sophisticated benchmarks that test deeper reasoning skills are essential steps. The comparison of different algorithmic approaches, similar to those explored in imbalanced classification \cite{wankmller2022comparisonapproaches} or statistical modeling \cite{wang2022comparisonthree}, could also inform the development of more effective reasoning systems. Ultimately, the goal is to create AI systems that can not only solve mathematical problems but also understand and contribute to the field of mathematics.

The implications of advanced LLM mathematical reasoning are vast, ranging from automated theorem proving and scientific discovery to more accessible educational tools and sophisticated financial modeling. However, the responsible development and deployment of these technologies require a deep understanding of their current limitations and a commitment to addressing ongoing research challenges.

=== CONCLUSION ===
\section{Conclusion}

This systematic literature review has provided a comprehensive overview of the current state of research concerning large language models (LLMs) and mathematical reasoning. Our findings indicate a rapidly evolving field with significant progress in enabling LLMs to perform a wide array of mathematical tasks, from arithmetic to complex word problem-solving \cite{lu2022surveydeep}. The advancements in prompting techniques, such as chain-of-thought reasoning \cite{wei2022chainofthought}, and the application of fine-tuning strategies have been instrumental in this progress.

Key contributions of this review include the identification of dominant tasks and datasets used for evaluation, a detailed categorization of methodologies employed to enhance LLM mathematical reasoning capabilities, and a synthesis of the current findings. We have highlighted the critical importance of robustness \cite{stolfo2022causalframework} and generalization as ongoing challenges, underscoring the need for deeper, more reliable reasoning beyond pattern matching.

The implications of this research are far-reaching, promising to revolutionize fields that rely heavily on quantitative analysis and logical deduction. Applications span scientific research, engineering, finance, and education, where LLMs could serve as powerful tools for problem-solving, discovery, and personalized learning.

However, significant research gaps remain, particularly concerning the interpretability of LLM reasoning processes and their ability to handle highly abstract or novel mathematical concepts. Future research should continue to explore innovative architectures, knowledge integration strategies \cite{hu2022surveyknowledge}, and rigorous evaluation methodologies. The development of LLMs that can truly reason mathematically, rather than merely mimic it, represents a crucial frontier in artificial intelligence.

In conclusion, while LLMs have demonstrated remarkable potential in mathematical reasoning, the journey towards fully autonomous and trustworthy mathematical AI is ongoing. This review serves as a valuable resource for researchers and practitioners, charting the current landscape and illuminating the path forward in this exciting and critical area of AI research.

=== END PREVIOUS DRAFT ===

UPDATED STATISTICS:
- Total papers now included: 30
- Records identified: 462
- Studies included: 462

TASK: COMPLETELY REGENERATE the paper integrating the new papers.

REGENERATION INSTRUCTIONS:
1. Read the previous draft to understand existing structure and themes
2. Review the NEW papers being added (listed in "NEW PAPERS BEING ADDED" section)
3. Integrate new papers throughout ALL sections where relevant
4. In Results section:
   - Add new subsections if new themes emerge from new papers
   - Reorganize existing subsections for better coherence
   - CITE every paper discussed using \cite{citationKey}
5. Update all statistics to reflect new paper count
6. Maintain academic quality and narrative flow
7. Ensure EVERY paper (old and new) is cited using \cite{citationKey}

CITATION REQUIREMENTS:
✓ Use \cite{citationKey} format (e.g., \cite{smith2020deep})
✓ Cite papers from BOTH previous draft AND new additions
✓ Introduction: MINIMUM 5-10 citations
✓ Results: MINIMUM 15-25 citations (more with larger paper count)
✓ Discussion: MINIMUM 10-15 citations
✓ Conclusion: MINIMUM 3-5 citations
✓ Each subsection in Results MUST cite papers relevant to that theme

REGENERATE COMPLETE PAPER:
1. ABSTRACT: Update with new paper count, refined findings (NO citations)
2. INTRODUCTION: Integrate relevant new papers, update scope, CITE extensively
3. METHODOLOGY: Update statistics (cite PRISMA guidelines if needed)
4. RESULTS: **CRITICAL** - Reorganize with new papers, cite ALL papers discussed
5. DISCUSSION: Integrate new findings, synthesize across all papers, CITE extensively
6. CONCLUSION: Update with insights from complete set, CITE key papers

CRITICAL: Return your response as VALID JSON with PROPER ESCAPING:

IMPORTANT JSON ESCAPING RULES:
- Every single backslash in LaTeX commands MUST be escaped as double backslash
- \cite{} becomes \\cite{} in JSON
- \subsection{} becomes \\subsection{} in JSON
- Example: "introduction": "Recent work \\cite{smith2020} shows..."

Return ONLY valid JSON in this EXACT format:
{
  "abstract": "...",
  "introduction": "text with \\cite{} properly escaped",
  "methodology": "...",
  "results": "text with \\subsection{} and \\cite{} properly escaped",
  "discussion": "text with \\cite{} properly escaped",
  "conclusion": "text with \\cite{} properly escaped"
}

VERIFY: Check that ALL backslashes are doubled (\\) in JSON before returning!
