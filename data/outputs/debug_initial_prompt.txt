
You are an expert in writing PRISMA systematic literature reviews for academic publication.

CRITICAL REQUIREMENT: You MUST cite papers using LaTeX \cite{} commands throughout the paper. Every claim, finding, or reference to a paper MUST include a citation.

=== BIBTEX ENTRIES (USE THESE CITATION KEYS) ===
@article{cohen2022thisunicorn,
  title={"This is my unicorn, Fluffy": Personalizing frozen vision-language representations},
  author={Niv Cohen and Rinon Gal and E. Meirom and Gal Chechik and Y. Atzmon},
  year={2022},
  booktitle={European Conference on Computer Vision},
  doi={10.48550/arXiv.2204.01694},
  url={https://www.semanticscholar.org/paper/0791a0441e1f672c43aecb2d6708fbc8725c8cad},
  abstract={Large Vision&Language models pretrained on web-scale data provide representations that are invaluable for numerous V&L problems. However, it is unclear how they can be used for reasoning about user-specific visual concepts in unstructured language. This problem arises in multiple domains, from personalized image retrieval to personalized interaction with smart devices. We introduce a new learning setup called Personalized Vision&Language (PerVL) with two new benchmark datasets for retrieving and segmenting user-specific"personalized"concepts"in the wild". In PerVL, one should learn personalized concepts (1) independently of the downstream task (2) allowing a pretrained model to reason about them with free language, and (3) does not require personalized negative examples. We propose an architecture for solving PerVL that operates by extending the input vocabulary of a pretrained model with new word embeddings for the new personalized concepts. The model can then reason about them by simply using them in a sentence. We demonstrate that our approach learns personalized visual concepts from a few examples and can effectively apply them in image retrieval and semantic segmentation using rich textual queries.}
}

@article{stolfo2022causalframework,
  title={A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models},
  author={Alessandro Stolfo and Zhijing Jin and Kumar Shridhar and B. Scholkopf and Mrinmaya Sachan},
  year={2022},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  doi={10.48550/arXiv.2210.12023},
  url={https://www.semanticscholar.org/paper/9b45af10429681249fafb07c3b6012ea4ce63ffe},
  abstract={We have recently witnessed a number of impressive results on hard mathematical reasoning problems with language models. At the same time, the robustness of these models has also been called into question; recent works have shown that models can rely on shallow patterns in the problem description when generating a solution.Building on the idea of behavioral testing, we propose a novel framework, which pins down the causal effect of various factors in the input, e.g., the surface form of the problem text, the operands, and math operators on the output solution.By grounding the behavioral analysis in a causal graph describing an intuitive reasoning process, we study the behavior of language models in terms of robustness and sensitivity to direct interventions in the input space. We apply our framework on a test bed of math word problems.Our analysis shows that robustness does not appear to continuously improve as a function of size, but the GPT-3 Davinci models (175B) achieve a dramatic improvement in both robustness and sensitivity compared to all other GPT variants.}
}

@article{snchez2022clusteringapproach,
  title={A Clustering Approach for the Optimal Siting of Recharging Stations in the Electric Vehicle Routing Problem with Time Windows},
  author={Danny García Sánchez and Alejandra Tabares and L. Faria and Juan Carlos Rivera and J. Franco},
  year={2022},
  booktitle={Energies},
  doi={10.3390/en15072372},
  url={https://www.semanticscholar.org/paper/f1164514c7180331c3b059c19eab5169c9c921a7},
  abstract={Transportation has been incorporating electric vehicles (EVs) progressively. EVs do not produce air or noise pollution, and they have high energy efficiency and low maintenance costs. In this context, the development of efficient techniques to overcome the vehicle routing problem becomes crucial with the proliferation of EVs. The vehicle routing problem concerns the freight capacity and battery autonomy limitations in different delivery-service scenarios, and the challenge of best locating recharging stations. This work proposes a mixed-integer linear programming model to solve the electric location routing problem with time windows (E-LRPTW) considering the state of charge, freight and battery capacities, and customer time windows in the decision model. A clustering strategy based on the k-means algorithm is proposed to divide the set of vertices (EVs) into small areas and define potential sites for recharging stations, while reducing the number of binary variables. The proposed model for E-LRPTW was implemented in Python and solved using mathematical modeling language AMPL together with CPLEX. Performed tests on instances with 5 and 10 clients showed a large reduction in the time required to find the solution (by about 60 times in one instance). It is concluded that the strategy of dividing customers by sectors has the potential to be applied and generate solutions for larger geographical areas and numbers of recharging stations, and determine recharging station locations as part of planning decisions in more realistic scenarios.}
}

@misc{desogus2022contributionrelationship,
  title={A Contribution on Relationship Banking. Economic, Anthropological and Mathematical Reasoning, Empirical Evidence from Italy},
  author={Marco Desogus and Elisa Casu},
  year={2022},
  url={https://www.semanticscholar.org/paper/dd88cc9b1f6d71ef82631b4e1c98c077ccdf291a}
}

@article{wang2022hybridgenetic,
  title={A Hybrid Genetic Algorithm for Flexible Job Shop Scheduling Problem},
  author={Xianglong Wang and Changyi Liu},
  year={2022},
  booktitle={2022 5th World Conference on Mechanical Engineering and Intelligent Manufacturing (WCMEIM)},
  doi={10.1109/WCMEIM56910.2022.10021523},
  url={https://www.semanticscholar.org/paper/3cff420b5a41a06291b68f5b6600935c090f8ad8},
  abstract={Partially flexible job shop scheduling problem (P-FJSP) is a NP Hard problem more complex than fully flexi-ble job shop scheduling problem (T -FJSP). In this paper, the mathematical model of flexible job shop scheduling is established with the goal of minimizing the maximum completion time (makespan). It combines the local search ability of simu-lated annealing algorithm and the global search ability of ge-netic algorithm. In the process of chromosome decoding, greedy decoding method is used to get a better scheduling solution as far as possible. The hybrid scheduling algorithm is implemented based on Visual Studio and C # language. Finally, 8×8 classic scheduling instance are used for simulation scheduling experiments to verify that the hybrid genetic algorithm proposed in this paper is effective in solving large-scale FJSP.}
}

@article{zhang2022multilayerattention,
  title={A Multi-Layer Attention Network for Visual Commonsense Reasoning},
  author={Wenqi Zhang and Yongchao Gao and Heng Qian and Hongli Lyu},
  year={2022},
  booktitle={International Conference on Data Science and Information Technology},
  doi={10.1109/DSIT55514.2022.9943834},
  url={https://www.semanticscholar.org/paper/0e0f20f3af3650b5a97b0ec3f046ba8160b45279},
  abstract={Visual Commonsense Reasoning (VCR) is a challenging multimodal task involving several research fields such as vision, cognition, and reasoning, which combines images and natural language for reasoning. Existing VCR methods focus on global attention or use pre-training models, but these methods lack attention to local features of visual and language. In this paper, a multi-layer attention network is proposed for the VCR task, including an intra-modal attention module and an inter-modal attention module. The intra-modal attention module complements important features of visual and language modalities with fine-grained visual attention to improve the relevance of visual and language. The inter-modal attention module captures the internal dependencies between visual and language. Finally, the two modules are integrated into an end-to-end reasoning framework. Experiments on the VCR large-scale dataset show that the proposed method exhibits a decent improvement in the VCR task and illustrates the effectiveness of the method on three subtasks.}
}

@article{ricci2022petrinetbasedapproach,
  title={A Petri-Net-Based Approach for Enhancing Clinical Reasoning in Medical Education},
  author={F. Ricci and F. Consorti and F. Pecoraro and D. Luzi and Oscar Tamburis},
  year={2022},
  journal={IEEE Transactions on Learning Technologies},
  doi={10.1109/tlt.2022.3157391},
  url={https://www.semanticscholar.org/paper/98b0fb67a6fb222998e3449621f3f5eecaed758e},
  abstract={Medical students are called to acquire competence to manage disease in its dynamic evolution over time, learning to analyze how clinical conditions evolve in a patient's history and how each condition interferes with the evolution of the other coexisting conditions. In this article, the health issue network (HIN) approach is introduced as a formal language based on Petri nets (PNs) to model properties that are particularly apposite for the graphical representation of HIN evolutionary paths. Moreover, the PNs’ underlying mathematical model allows users to draw coherent and well-formed graphs representing rather complex clinical cases. Finally, HIN can be easily integrated into a simulation environment to support case-based learning activities and assessment. The examples of the exercises provided in this article show, on the one hand, the ways the introduced methodology is figured out and implemented; on the other hand, they outline the variety of learning questions that users may deal with when deploying the HIN approach.}
}

@article{ekong2022ratiocinativestudy,
  title={A Ratiocinative Study and Assessment of W. V. O. Quine’s “Criterion of Ontological Commitment”},
  author={Joseph T. Ekong},
  year={2022},
  journal={International Journal of Philosophy},
  doi={10.47941/ijp.1052},
  url={https://www.semanticscholar.org/paper/7b6955111d3bd91b13e7a9c7fbdfd75d43825c36},
  abstract={Purpose: This work has three main objectives: Firstly, it offers an elucidation of the notion of ontological commitment. Secondly, it assesses the adequacy of the criterion of ontological commitment for different languages. Thirdly, it offers some speculative and evaluative remarks regarding the significance of Quine’s criterion of ontological commitment. Many ontologists, within the analytic tradition, often appeal to Quine's criterion of ontological commitment, when debating whether an assertion or theory implies the existence of a certain entity. Regarding his goal in formulating this criterion, he says that the criterion does not aim to help us discover what it is that there is, but only what a theory says there is: “I look to variables and quantification for evidence as to what a theory says that there is, not for evidence as to what there is” (Quine, 1960: 225). Its most popular formulation, using textual evidence from Quine's oeuvre, is: “To be is to be the value of a bound variable,” (Quine, 1961: 15). However, this formulation is susceptible to gross misunderstanding, especially if one is influenced by the formalities and technical maneuvers of model theory. In mathematical logic, model theory is the study of the relationship between formal theories (a collection of sentences in a formal language expressing statements about a mathematical structure), and their models (those structures in which the statements of the theory hold). Model theory is a branch of mathematical logic where we study mathematical structures by considering the first-order sentences true in those structures and the sets definable by first-order formulas. Model theory studies the relations between sentences of a formal language and the interpretations (or ‘structures’) which make these sentences true or false. It offers precise definitions of truth, logical truth and consequence, meanings and modalities. 
Methodology: This work is expository, analytic, critical and evaluative in its methodology. Of course, there are familiar philosophical problems which are within the discursive framework of ‘ontology,’ often phrased by asking if something or some category of things are “real,” or whether “they exist,” concretely. An outstanding example is provided by the traditional problem of universals, which issues in the nominalist-realist controversy, as to the real existence of universals, or of abstract entities such as classes (in the mathematical sense) or propositions (in the abstract sense, referring to the content of an assertion in abstraction from the particular words used to convey it). 
Results: In as much as one might agree with Quine’s Criterion of Ontological Commitment, one might also opine that it is nonetheless a feature of first-order language (i.e. the language embodied in first-order logic; a symbolized reasoning process comprising relations, functions and constants, in which each sentence or statement is broken down into a subject and a predicate. In this regard, the predicate modifies or defines the properties of the subject) that there should be an exact correspondence between the ontological commitments carried by a sentence and the objects that must be counted among the values of the variables in order for the sentence to be true. However, this in itself is not a reason for thinking that such a feature will generalize beyond first-order languages. It is possible for Quine’s Criterion to degenerate, when the language contains atomic predicates expressing extrinsic properties. 
Unique Contribution to theory, practice and policy: Based on Quine’s analysis, a theory is committed to those and only those entities that in the last analysis serve as the values of its bound variables. Thus, ordinary first-order theory commits one to an ontology only of individuals (particulars), whereas higher order logic commits one to the existence of sets, i.e. of collections of definite and distinct entities (or, alternatively, of properties and relations). Likewise, if bound first-order variables are assumed to range over sets (as they do in set theory), a commitment to the existence of these sets is incurred. Admittedly, the precise import of Quine’s criterion of ontological commitment, however, is not completely clear, nor is it clear in what other sense one is perhaps committed by a theory to those entities that are named or otherwise referred to in it, but not quantified over in it. However, it despite its limitations, it has made is possible for one to measure the ontological cost of theories, an important component in deciding which theories to accept, thus offering a partial foundation for theory choice.}
}

@article{li2022scenariobasedexploration,
  title={A Scenario-based Exploration of Expected Usefulness, Privacy Concerns, and Adoption Likelihood of Learning Analytics},
  author={X. Li and M. Rosson and Jenay Robert},
  year={2022},
  booktitle={ACM Conference on Learning @ Scale},
  doi={10.1145/3491140.3528271},
  url={https://www.semanticscholar.org/paper/067b8489b028d931b751cb9413225b761e51dcf3},
  abstract={Learning analytics has become a robust research area in the last decade, as innovative analytic models of learning data have been created with the goal of enhancing teaching and learning. However, barriers to large scale adoption of such technologies in higher education still exist. In recent years, a strand of research has begun to investigate stakeholders' expectations of learning analytics, hoping to find ways to integrate the innovations into everyday teaching practices. For instance, studies have investigated instructors' ideas about how learning analytics might be helpful, as well as concerns about student data privacy. However, most studies have taken a general approach rather than considering instructors' day-to-day experiences. Using survey methods, we presented instructors with hypothetical scenarios of learning analytics in use across disciplines, class sizes, teaching activities, and types of student data. We asked for ratings of both usefulness and privacy concerns for each proposed teaching situation. Our respondents considered scenarios involving learning outcomes-related data (e.g. grades) to be more useful than those that involve student interactions (e.g. language, social activity). In contrast, privacy concerns were lower for outcomes-oriented scenarios than interactions-focused scenarios. An interesting new finding was a negative correlation of usefulness and privacy; we discuss this in the context of instructors' possible cost-benefit reasoning. We reflect on our findings with respect to future efforts in developing and fielding learning analytics tools.}
}

@article{lu2022surveydeep,
  title={A Survey of Deep Learning for Mathematical Reasoning},
  author={Pan Lu and Liang Qiu and Wenhao Yu and S. Welleck and Kai-Wei Chang},
  year={2022},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  doi={10.48550/arXiv.2212.10535},
  url={https://www.semanticscholar.org/paper/2dbec38fe353ab0e495ad09263389dbc9260824d},
  abstract={Mathematical reasoning is a fundamental aspect of human intelligence and is applicable in various fields, including science, engineering, finance, and everyday life. The development of artificial intelligence (AI) systems capable of solving math problems and proving theorems in language has garnered significant interest in the fields of machine learning and natural language processing. For example, mathematics serves as a testbed for aspects of reasoning that are challenging for powerful deep learning models, driving new algorithmic and modeling advances. On the other hand, recent advances in large-scale neural language models have opened up new benchmarks and opportunities to use deep learning for mathematical reasoning. In this survey paper, we review the key tasks, datasets, and methods at the intersection of mathematical reasoning and deep learning over the past decade. We also evaluate existing benchmarks and methods, and discuss future research directions in this domain.}
}

@article{hu2022surveyknowledge,
  title={A Survey of Knowledge Enhanced Pre-Trained Language Models},
  author={Linmei Hu and Zeyi Liu and Ziwang Zhao and Lei Hou and Liqiang Nie and Juanzi Li},
  year={2022},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  doi={10.1109/TKDE.2023.3310002},
  url={https://www.semanticscholar.org/paper/a26623d52d24e03044a158cddad931ec5ab7304c},
  abstract={Pre-trained Language Models (PLMs) which are trained on large text corpus via self-supervised learning method, have yielded promising performance on various tasks in Natural Language Processing (NLP). However, though PLMs with huge parameters can effectively possess rich knowledge learned from massive training text and benefit downstream tasks at the fine-tuning stage, they still have some limitations such as poor reasoning ability due to the lack of external knowledge. Research has been dedicated to incorporating knowledge into PLMs to tackle these issues. In this paper, we present a comprehensive review of Knowledge Enhanced Pre-trained Language Models (KE-PLMs) to provide a clear insight into this thriving field. We introduce appropriate taxonomies respectively for Natural Language Understanding (NLU) and Natural Language Generation (NLG) to highlight these two main tasks of NLP. For NLU, we divide the types of knowledge into four categories: linguistic knowledge, text knowledge, knowledge graph (KG), and rule knowledge. The KE-PLMs for NLG are categorized into KG-based and retrieval-based methods. Finally, we point out some promising future directions of KE-PLMs.}
}

@article{zhou2022surveyneural,
  title={A Survey on Neural Open Information Extraction: Current Status and Future Directions},
  author={Shaowen Zhou and Yu Bowen and Aixin Sun and Cheng Long and Jingyang Li and Haiyang Yu and Jianguo Sun},
  year={2022},
  booktitle={International Joint Conference on Artificial Intelligence},
  doi={10.48550/arXiv.2205.11725},
  url={https://www.semanticscholar.org/paper/5de6ecf62f14c9263882f9f30d6448df9efd34e0},
  abstract={Open Information Extraction (OpenIE) facilitates domain-independent discovery of relational facts from large corpora. The technique well suits many open-world natural language understanding scenarios, such as automatic knowledge base construction, open-domain question answering, and explicit reasoning. Thanks to the rapid development in deep learning technologies, numerous neural OpenIE architectures have been proposed and achieve considerable performance improvement. In this survey, we provide an extensive overview of the state-of-the-art neural OpenIE models, their key design decisions, strengths and weakness. Then, we discuss limitations of current solutions and the open issues in OpenIE problem itself. Finally we list recent trends that could help expand its scope and applicability, setting up promising directions for future research in OpenIE. To our best knowledge, this paper is the first review on neural OpenIE.}
}

@article{wankmller2022comparisonapproaches,
  title={A comparison of approaches for imbalanced classification problems in the context of retrieving relevant documents for an analysis},
  author={Sandra Wankmüller},
  year={2022},
  journal={Journal of Computational Social Science},
  doi={10.1007/s42001-022-00191-7},
  url={https://www.semanticscholar.org/paper/a12e9a6863c8453787575172599389d2ddcd9f62},
  abstract={One of the first steps in many text-based social science studies is to retrieve documents that are relevant for an analysis from large corpora of otherwise irrelevant documents. The conventional approach in social science to address this retrieval task is to apply a set of keywords and to consider those documents to be relevant that contain at least one of the keywords. But the application of incomplete keyword lists has a high risk of drawing biased inferences. More complex and costly methods such as query expansion techniques, topic model-based classification rules, and active as well as passive supervised learning could have the potential to more accurately separate relevant from irrelevant documents and thereby reduce the potential size of bias. Yet, whether applying these more expensive approaches increases retrieval performance compared to keyword lists at all, and if so, by how much, is unclear as a comparison of these approaches is lacking. This study closes this gap by comparing these methods across three retrieval tasks associated with a data set of German tweets (Linder in SSRN, 2017. https://doi.org/10.2139/ssrn.3026393 ), the Social Bias Inference Corpus (SBIC) (Sap et al. in Social bias frames: reasoning about social and power implications of language. In: Jurafsky et al. (eds) Proceedings of the 58th annual meeting of the association for computational linguistics. Association for Computational Linguistics, p 5477–5490, 2020. https://doi.org/10.18653/v1/2020.aclmain.486 ), and the Reuters-21578 corpus (Lewis in Reuters-21578 (Distribution 1.0). [Data set], 1997. http://www.daviddlewis.com/resources/testcollections/reuters21578/ ). Results show that query expansion techniques and topic model-based classification rules in most studied settings tend to decrease rather than increase retrieval performance. Active supervised learning, however, if applied on a not too small set of labeled training instances (e.g. 1000 documents), reaches a substantially higher retrieval performance than keyword lists.}
}

@article{wang2022comparisonthree,
  title={A comparison of three approaches to covariate effects on latent factors},
  author={Ze Wang},
  year={2022},
  booktitle={Large-scale Assessments in Education},
  doi={10.1186/s40536-022-00148-2},
  url={https://www.semanticscholar.org/paper/c40412109167ae57baab6505edf9b628efca6d3a},
  abstract={In educational and psychological research, it is common to use latent factors to represent constructs and then to examine covariate effects on these latent factors. Using empirical data, this study applied three approaches to covariate effects on latent factors: the multiple-indicator multiple-cause (MIMIC) approach, multiple group confirmatory factor analysis (MG-CFA) approach, and the structural equation model trees (SEM Trees) approach. The MIMIC approach directly models covariate effects on latent factors. The MG-CFA approach allows testing of measurement invariance before latent factor means could be compared. The more recently developed SEM Trees approach partitions the sample into homogenous subsets based on the covariate space; model parameters are estimated separately for each subgroup. We applied the three approaches using an empirical dataset extracted from the eighth-grade U.S. data from the Trends in International Mathematics and Science Study 2019 database. All approaches suggested differences among mathematics achievement categories for the latent factor of mathematics self-concept. In addition, language spoken at home did not seem to affect students’ mathematics self-concept. Despite these general findings, the three approaches provided different pieces of information regarding covariate effects. For all models, we appropriately considered the complex data structure and sampling weights following recent recommendations for analyzing large-scale assessment data.}
}

@misc{alemany2022methodologycharacterize,
  title={A methodology to characterize bias and harmful stereotypes in natural language processing in Latin America},
  author={L. A. Alemany and Luciana Benotti and Hernán Maina and Luc'ia M. Gonz'alez and Mariela Rajngewerc and Lautaro Mart'inez and Jos'e L. S'anchez and M. Schilman and Guido Ivetta and Alexia Halvorsen and Amanda Rojo and M. Bordone and Beatriz Busaniche},
  year={2022},
  url={https://www.semanticscholar.org/paper/a82a08b5e6a11f4d6fdff95dd30177957ed7855e},
  abstract={Automated decision-making systems, especially those based on natural language processing, are pervasive in our lives. They are not only behind the internet search engines we use daily, but also take more critical roles: selecting candidates for a job, determining suspects of a crime, diagnosing autism and more. Such automated systems make errors, which may be harmful in many ways, be it because of the severity of the consequences (as in health issues) or because of the sheer number of people they affect. When errors made by an automated system affect a population more than others, we call the system \textit{biased}. Most modern natural language technologies are based on artifacts obtained from enormous volumes of text using machine learning, namely language models and word embeddings. Since they are created by applying subsymbolic machine learning, mostly artificial neural networks, they are opaque and practically uninterpretable by direct inspection, thus making it very difficult to audit them. In this paper, we present a methodology that spells out how social scientists, domain experts, and machine learning experts can collaboratively explore biases and harmful stereotypes in word embeddings and large language models. Our methodology is based on the following principles: * focus on the linguistic manifestations of discrimination on word embeddings and language models, not on the mathematical properties of the models * reduce the technical barrier for discrimination experts%, be it social scientists, domain experts or other * characterize through a qualitative exploratory process in addition to a metric-based approach * address mitigation as part of the training process, not as an afterthought}
}

=== END BIBTEX ENTRIES ===

SEARCH PARAMETERS:
- Keywords: large language model, mathematical reasoning
- Inclusion criteria: large language model, mathematical reasoning
- Exclusion criteria: survey, review

PRISMA STATISTICS:
- Records identified: 462
- Records removed: 0
- Records screened: 462
- Records excluded: 0
- Studies included: 462

CITATION EXAMPLES (YOU MUST FOLLOW THIS FORMAT):
- Single citation: "Recent advances in transformer architectures \cite{vaswani2017attention} have enabled..."
- Multiple citations: "Several studies \cite{brown2020language,radford2019language,devlin2018bert} have demonstrated..."
- Citation in parentheses: "Deep learning has shown promise (see \cite{lecun2015deep} for a review)."

Generate a COMPLETE systematic literature review with these sections:

1. ABSTRACT (200-300 words)
   - State purpose, methodology, key findings, implications
   - Citations NOT needed in abstract (abstract should be citation-free)

2. INTRODUCTION (500-800 words)
   - Background on the topic - CITE foundational papers
   - Motivation for this review - CITE relevant work
   - Research questions
   - Brief PRISMA overview
   - Paper structure
   - MINIMUM 5-10 citations using \cite{citationKey}

3. METHODOLOGY (600-1000 words)
   - Detailed search strategy
   - Inclusion and exclusion criteria
   - Screening process
   - Quality assessment
   - Reference PRISMA flow
   - Citations only if referring to PRISMA guidelines or methodological papers

4. RESULTS (800-1200 words)
   - Overview statistics
   - Publication trends over time
   - Key venues/journals
   - Create thematic subsections using \subsection{Theme Name}
   - CITE papers extensively in each subsection
   - Every paper discussed MUST be cited with \cite{}
   - MINIMUM 15-20 citations throughout Results section

5. DISCUSSION (700-1000 words)
   - Synthesize findings - CITE supporting papers
   - Identify research gaps - CITE papers that highlight gaps
   - Implications - CITE relevant work
   - Limitations
   - Future directions - CITE papers suggesting future work
   - MINIMUM 10-15 citations

6. CONCLUSION (300-500 words)
   - Summarize main findings - CITE key papers
   - Contribution of this review
   - Practical implications - CITE relevant applications
   - Final thoughts
   - MINIMUM 3-5 citations of most important papers

MANDATORY REQUIREMENTS:
✓ Every section (except abstract) MUST contain \cite{} commands
✓ Use ONLY the citation keys from the BibTeX entries above
✓ Format: \cite{citationkey} NOT cite{} or [citationkey]
✓ Return LaTeX-formatted text with proper citation commands
✓ Results section MUST have subsections organized by theme
✓ Each claim about a paper MUST have a citation

CRITICAL: Return your response as VALID JSON with PROPER ESCAPING:

IMPORTANT JSON ESCAPING RULES:
- Every single backslash in LaTeX commands MUST be escaped as double backslash
- \cite{} becomes \\cite{} in JSON
- \section{} becomes \\section{} in JSON
- \subsection{} becomes \\subsection{} in JSON
- Example: "text": "Recent work \\cite{smith2020} shows..."

Return ONLY valid JSON in this EXACT format:
{
  "abstract": "text with no citations",
  "introduction": "text with \\cite{citationkey} commands properly escaped",
  "methodology": "text with \\cite{} commands properly escaped if needed",
  "results": "text with \\subsection{} and \\cite{} commands properly escaped",
  "discussion": "text with \\cite{} commands properly escaped",
  "conclusion": "text with \\cite{} commands properly escaped"
}

VERIFY: Before returning, check that ALL backslashes are doubled (\\) in the JSON!
